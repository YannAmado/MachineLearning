{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f81979df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#we will be using a fixed seed as to make our network behave equally between runs\n",
    "np.random.seed(9)\n",
    "class Network:\n",
    "    def __init__(self, nInputs, nHiddenLayers, nNeuronsPerHL, nOutputs):\n",
    "        totalLayers = nHiddenLayers + 2 # total layers = (one input+ nHiddenLayers+ one output)\n",
    "        self.totalLayers = totalLayers\n",
    "        self.nInputs = nInputs\n",
    "        self.nHiddenLayers = nHiddenLayers\n",
    "        self.nNeuronsPerHL = nNeuronsPerHL\n",
    "        self.nOutputs = nOutputs\n",
    "        \n",
    "        #initializing the weights and biases randomly using a gaussian distribution with mean 0 and standard deviation 1\n",
    "        sizes = [nInputs]\n",
    "        for i in range(nHiddenLayers):\n",
    "            sizes.append(nNeuronsPerHL)\n",
    "        sizes.append(nOutputs)\n",
    "        self.biases = [np.random.normal(loc=0, scale=1, size=s) for s in sizes[1:None]]                    #which layer, which neuron\n",
    "\n",
    "        self.weights =[np.random.normal(loc=0, scale=1, size=(x,y)) for x,y in zip(sizes[:None], sizes[1:])]\n",
    "        #which layer, which neuron, which weight\n",
    "        #to access the 1st weight layer 5th exiting neuron 10th arriving neuron: network.weights[0][4][9]\n",
    "        #+1 because the number of weight layers is the total number of layers - 1\n",
    "        self.zActivations = [np.zeros(s) for s in sizes[1:None]]\n",
    "        self.activations = [np.zeros(s) for s in sizes]\n",
    "        \n",
    "def sigmoid(number):\n",
    "    sigNumber = 1/(1 + np.exp(-number))\n",
    "    return sigNumber  \n",
    "\n",
    "def feedforward(network: Network):\n",
    "    givingLayer = 0\n",
    "    # looping until the last layer\n",
    "    while givingLayer < network.totalLayers-1:                 \n",
    "        if givingLayer == 0:                           #if its the input layer\n",
    "            nGivingNeurons = network.nInputs\n",
    "            nReceivingNeurons = network.nNeuronsPerHL\n",
    "        elif givingLayer == network.totalLayers-2: #if its the layer before the output layer\n",
    "            nGivingNeurons = network.nNeuronsPerHL\n",
    "            nReceivingNeurons = network.nOutputs\n",
    "        else:                                          #if its any layer inbetween\n",
    "            nGivingNeurons = network.nNeuronsPerHL\n",
    "            nReceivingNeurons = network.nNeuronsPerHL\n",
    "        currentLayer = 0\n",
    "        #for each neuron in the layer being fed    \n",
    "        for receivingNeuron in range(nReceivingNeurons):\n",
    "            #the activation of the current neuron is its own biases + all the weights*activations of the previous layer\n",
    "            activation = network.biases[currentLayer][receivingNeuron]\n",
    "            for givingNeuron in range(nGivingNeurons):\n",
    "                activation += network.weights[givingLayer][givingNeuron][receivingNeuron]*network.activations[givingLayer][givingNeuron]\n",
    "            network.activations[givingLayer+1][receivingNeuron] = sigmoid(activation)\n",
    "            \n",
    "        givingLayer += 1\n",
    "        currentLayer += 1\n",
    "    \n",
    "    return network\n",
    "\n",
    "def classify(network: Network):\n",
    "    maxIndex = np.argmax(network.activations[-1])\n",
    "    return maxIndex, network.activations[-1][maxIndex]\n",
    "\n",
    "from keras.datasets import mnist\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c25945bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidDerivative(number):\n",
    "    return sigmoid(number)*(1-sigmoid(number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e376769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCostVector(network: Network, rightNumber):\n",
    "    lastLayer = -1\n",
    "    cost = np.zeros(network.nOutputs)\n",
    "    for i in range(network.nOutputs):\n",
    "        if i+1 == rightNumber:\n",
    "            cost[i] = (network.activations[lastLayer][i] - 1)**2 \n",
    "        else:\n",
    "            cost[i] = (network.activations[lastLayer][i] - 0)**2 \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f40fd093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCostDerivative(network: Network, rightNumber):\n",
    "    lastLayer = -1\n",
    "    cost = np.zeros(network.nOutputs)\n",
    "    for i in range(network.nOutputs):\n",
    "        if i == rightNumber:\n",
    "            cost[i] = 2*(network.activations[lastLayer][i] - 1)\n",
    "        else:\n",
    "            cost[i] = 2*(network.activations[lastLayer][i] - 0)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e29a12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setActivations(network: Network, img):\n",
    "        #passing the inputs to our network\n",
    "        for i in range(28):\n",
    "            for j in range(28):\n",
    "                network.activations[0][28*i + j] = img[i][j]\n",
    "        return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "781948d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backPropagation(network: Network, xBatch, yBatch, batchSize, learningRate):\n",
    "    eta = learningRate\n",
    "    \n",
    "    size = []\n",
    "    size.append(network.nInputs)\n",
    "    for i in range(network.nHiddenLayers):\n",
    "        size.append(network.nNeuronsPerHL)\n",
    "    size.append(network.nOutputs)\n",
    "    delta_l = [np.zeros(s) for s in size[:None]]\n",
    "    # recreating the shape of the biases and weights\n",
    "    nablaB = np.empty_like(network.biases)\n",
    "    nablaW = np.empty_like(network.weights)\n",
    "    #-1 because array and -1 because the last layer will not be iterated and -1 because the first layer has no bias\n",
    "    for img in range(batchSize):\n",
    "        network = setActivations(network, xBatch[img])\n",
    "        network = feedforward(network)\n",
    "        delta_l[-1] = 2*findCostDerivative(network, yBatch[img])*sigmoidDerivative(network.zActivations[-1])\n",
    "        \n",
    "        # finding dC/dW and dC/dB\n",
    "        for l in range(network.totalLayers-2, -1, -1): \n",
    "            if l == 0:\n",
    "                delta_l[l] += np.dot(network.weights[l].T, delta_l[l+1])*sigmoidDerivative(network.zActivations[l])\n",
    "                nablaB[l] += delta_l[l]\n",
    "                nablaW[l] += np.dot(network.activations[l-1], delta_l[l])\n",
    "    print(f\"delta 0: {delta_l[0,0]},\" \n",
    "              f\"delta 1: {delta_l[1,0]},\" \n",
    "              f\"delta 2: {delta_l[2,0]}\")\n",
    "    \n",
    "    # taking the averages\n",
    "    nablaB = nablaB/batchSize\n",
    "    nablaW = nablaW/batchSize\n",
    "    # adjusting the network\n",
    "    for i in range(network.totalLayers-2):\n",
    "        network.biases[i] = network.biases[i] - eta*nablaB[i]\n",
    "        network.weights[i] = network.weights[i] - eta*nablaW[i]\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10332287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(network: Network, trainX, trainY, batchSize, epochs, learningRate):\n",
    "    \n",
    "    # shuffling\n",
    "    trainingImages = list(zip(trainX, trainY))\n",
    "    random.shuffle(trainingImages)\n",
    "    trainX, trainY = zip(*trainingImages)\n",
    "\n",
    "    for currentEpoch in range(epochs):\n",
    "        yBatch = trainY[currentEpoch*batchSize: (currentEpoch + 1)*batchSize]\n",
    "        xBatch = trainX[currentEpoch*batchSize: (currentEpoch + 1)*batchSize]\n",
    "        # print(\"before: \", network.weights[0,0][0], network.biases[0,0])\n",
    "        network = backPropagation(network, xBatch, yBatch, batchSize, learningRate)\n",
    "        # print(\"after: \", network.weights[0,0][0], network.biases[0,0])\n",
    "        hits = 0\n",
    "        misses = 0\n",
    "        numbersThinked = np.zeros(10)\n",
    "        trainXX = trainX[currentEpoch*batchSize: (currentEpoch + 1)*batchSize]\n",
    "        trainYY = trainY[currentEpoch*batchSize: (currentEpoch + 1)*batchSize]\n",
    "        for imgX, imgY in zip(trainXX, trainYY):\n",
    "            network = setActivations(network, imgX)\n",
    "            network = feedforward(network)\n",
    "            numberNetworkThinks, certainty = classify(network)\n",
    "            numbersThinked[numberNetworkThinks] += 1 \n",
    "            if numberNetworkThinks == imgY:\n",
    "                hits += 1\n",
    "            else:\n",
    "                misses += 1\n",
    "        acc = hits/misses\n",
    "        print(f'epoch {currentEpoch+1}, accuracy = {acc}, numbers guessed = {numbersThinked}')\n",
    "    return network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7696f673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "<ipython-input-1-1ddd3759b107>:31: RuntimeWarning: overflow encountered in exp\n",
      "  sigNumber = 1/(1 + np.exp(-number))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (30,784) and (30,) not aligned: 784 (dim 1) != 30 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f5641489c7c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmisses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnTrainingImages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mnetwork\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearningRate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-3e553726a593>\u001b[0m in \u001b[0;36mSGD\u001b[1;34m(network, trainX, trainY, batchSize, epochs, learningRate)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mxBatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrentEpoch\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcurrentEpoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# print(\"before: \", network.weights[0,0][0], network.biases[0,0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mnetwork\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackPropagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxBatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myBatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearningRate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;31m# print(\"after: \", network.weights[0,0][0], network.biases[0,0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mhits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-9c1daba8af87>\u001b[0m in \u001b[0;36mbackPropagation\u001b[1;34m(network, xBatch, yBatch, batchSize, learningRate)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotalLayers\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ml\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                 \u001b[0mdelta_l\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta_l\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msigmoidDerivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzActivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m                 \u001b[0mnablaB\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdelta_l\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0mnablaW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta_l\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (30,784) and (30,) not aligned: 784 (dim 1) != 30 (dim 0)"
     ]
    }
   ],
   "source": [
    "network = Network(28*28, 1, 30, 10)\n",
    "hits = 0\n",
    "misses = 0\n",
    "nTrainingImages = trainX.shape[0]\n",
    "network = SGD(network, trainX, trainY, batchSize=100, epochs=100, learningRate = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee91fb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
