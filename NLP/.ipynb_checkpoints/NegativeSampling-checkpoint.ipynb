{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44cd3262",
   "metadata": {},
   "source": [
    "Implementing a Neural Network with negative sampling for word2vec task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14a426d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67dbe35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \"\"\"\n",
    "    The main object we're going to use accross this notebook\n",
    "    It's a neural network that takes as input a list of \n",
    "    layers nodes\n",
    "    \n",
    "    Ex: [2, 3, 1] is a 3 layer network, with 2 neurons of input, 3 neurons \n",
    "    in the hidden layer and 1 for the output layer\n",
    "    \n",
    "    Supposedly it can take more than just 3 layers but I didnt test it\n",
    "    \n",
    "    It initializes an object with the proper weights, biases, activations and z\n",
    "    based on the layers list. It also has the layers list and the number of layers\n",
    "    \n",
    "    The weights and biases initialized following a Gaussian with standard deviation 1/sqrt(n_in)\n",
    "    with n_in = number of weights into the neuron\n",
    "    \"\"\"\n",
    "    def __init__(self, layers: list):        \n",
    "        np.random.seed(42)        \n",
    "        b = []\n",
    "        w = []\n",
    "        a = []\n",
    "        z = []\n",
    "        for l in range(0, len(layers)):\n",
    "            # skipping one layer for the weights and biases\n",
    "            if (l+1) < len(layers):\n",
    "                b.append(np.random.normal(loc=0, scale=1,size=layers[l+1]))\n",
    "                wScale = 1/np.sqrt(layers[l])\n",
    "                w.append(np.random.normal(loc=0,scale=wScale,size=[layers[l],layers[l+1]]))\n",
    "                #print(w[l])\n",
    "            a.append(np.zeros(layers[l]))\n",
    "            z.append(np.zeros(layers[l]))\n",
    "        # b[i][j] -> \"i\" is which layer, \"j\" which neuron\n",
    "        # w[i][j][k] -> \"i\" is which layer, \"j\" which neuron of the first layer, \"k\" which neuron of the second layer\n",
    "        self.b = b\n",
    "        self.w = w\n",
    "        self.a = a\n",
    "        self.z = z\n",
    "        self.nLayers = len(layers)\n",
    "        self.layers = layers\n",
    "        \n",
    "    @staticmethod\n",
    "    def copy(net):\n",
    "        copiedNet = Network([784,30,10])\n",
    "        copiedNet.a = np.copy(net.a)\n",
    "        copiedNet.z = np.copy(net.z)\n",
    "        for l in range(2):\n",
    "            copiedNet.w[l] = np.copy(net.w[l])\n",
    "            copiedNet.b[l] = np.copy(net.b[l])\n",
    "        return copiedNet\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "378ffc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(n: float):\n",
    "    return 1.0/(1.0+np.exp(-n))\n",
    "\n",
    "def sigmoid_derivative(n: float):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(n)*(1-sigmoid(n))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ea48a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedForward(net: Network) -> Network:\n",
    "    \"\"\"\n",
    "    Feedforwading the activations to the next layer\n",
    "    \n",
    "    It will take as input the network already with the input image as the activation \n",
    "    on the first layer and then feedforward to the next layrse\n",
    "    \n",
    "    It returns the network with all the activations set\n",
    "    \"\"\"\n",
    "    \n",
    "    # resetting the activations as to not take any info from the activation of\n",
    "    # the previous number while maintanin the first activation\n",
    "    for i in range(1, net.nLayers):\n",
    "        net.z[i] = np.zeros(net.layers[i])\n",
    "        net.a[i] = np.zeros(net.layers[i])\n",
    "    for l in range(0, net.nLayers-1):\n",
    "        for receivingNeuron in range(net.layers[l+1]):\n",
    "            for givingNeuron in range(net.layers[l]):\n",
    "                net.z[l+1][receivingNeuron] += net.a[l][givingNeuron] * net.w[l][givingNeuron][receivingNeuron]\n",
    "            net.z[l+1][receivingNeuron] += net.b[l][receivingNeuron]\n",
    "            net.a[l+1][receivingNeuron] = sigmoid(net.z[l+1][receivingNeuron])\n",
    "\n",
    "            \n",
    "    return net\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10120406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setInput(net: Network, oneHotTokens):\n",
    "    \"\"\"\n",
    "    Inputs the MNIST number into the network, since the number is a 28x28 matrix, \n",
    "    we transform it into a 784 array\n",
    "    \n",
    "    We also scale the pixels as to be between 0 and 1 for the sigmoid function \n",
    "    instead of 0 and 255\n",
    "    \n",
    "    Returns the network with the proper activations on all layers since it pass \n",
    "    through the feedforward step\n",
    "    \"\"\"\n",
    "    for i in range(net.layers[0]):\n",
    "        net.z[0][i] = oneHotTokens[i]\n",
    "        net.a[0][i] = oneHotTokens[i]\n",
    "    net = feedForward(net)\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d026ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testNetwork(net: Network, test_X, test_y, nTests: int):\n",
    "    \"\"\"\n",
    "    A function to test our network\n",
    "    \n",
    "    It returns the overall accuracy and the numbers our network guessed\n",
    "    \"\"\"\n",
    "    \n",
    "    correctOutput = 0\n",
    "    X = test_X[:nTests]\n",
    "    y = test_y[:nTests]\n",
    "    outputs = np.zeros((net.layers[-1]))\n",
    "    for i in range(nTests):\n",
    "        net = setInput(net, X[i])\n",
    "        networkOutput = np.argmax(net.a[-1])\n",
    "        outputs[networkOutput] += 1\n",
    "        #print(f\"number: {y[i]}, networkOutput: {networkOutput}, activations: {net.a[-1]}\")\n",
    "        if y[i] == networkOutput:\n",
    "            correctOutput += 1\n",
    "    acc = correctOutput/nTests\n",
    "    return acc, outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d4f2b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch(train_X, train_y, test_X, test_y, batchSize: int, learningRates: list, epochs: int, lamb):\n",
    "    \"\"\"\n",
    "    A function to perform a gridSearch in order to find the best learningRates\n",
    "\n",
    "    It takes as input the network, the training images of MNIST, the training labels,\n",
    "    the test images, the test labels, the batchSize for SGD,\n",
    "    a list of learningRates as to find the best inside the list\n",
    "    the number of epochs to perform SGD\n",
    "    \n",
    "    \n",
    "    It returns the best network accross all learning rates list\n",
    "    \"\"\"\n",
    "    bestAcc = 0\n",
    "    for eta in learningRates:\n",
    "        # resetting the network\n",
    "        net = Network([784,30,10])\n",
    "        net = SGD(net, train_X, train_y, batchSize=batchSize, nEpochs=epochs, learningRate=eta, lamb=lamb)\n",
    "        acc, outputs = testNetwork(net, test_X, test_y, batchSize) \n",
    "        if acc > bestAcc:\n",
    "            bestNet = net\n",
    "            bestAcc = acc\n",
    "    return bestNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6491dbfe",
   "metadata": {},
   "source": [
    "The list below is all equations that were used to compute the erros and then propagate through the network:\n",
    "\n",
    "To calculate the error on the last layer: \n",
    "$$\\delta^L = (a^L - y)\\odot \\sigma'(z^L)$$\n",
    "\n",
    "To calculate the error on the other layers:\n",
    "$$\\delta^l = ((w^{l+1})^T\\delta^{l+1})\\odot \\sigma'(z^l)$$\n",
    "\n",
    "To repass the error to the bias: \n",
    "$$\\frac{\\partial C}{\\partial b^l_j} = \\delta^l_j$$\n",
    "\n",
    "To repass the error to the weights:\n",
    "$$\\frac{\\partial C}{\\partial w^l_{jk}} = a^{l-1}_k\\delta^l_j$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b397ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backProp(net: Network, y, nNegSamples, table) -> Network:\n",
    "    \"\"\"\n",
    "    The backpropagation step: first we calculate the error on the last layer, \n",
    "    then we pass to the previous layers all the while applying the error \n",
    "    to the weights and biases. Here we used Cross-entropy as our cost function\n",
    "    \n",
    "    Example on a 3 layer network: We calculate the error on the last layer, \n",
    "    apply it to the last layer's weights and biases, and then calculate the \n",
    "    error on the next layer, propagate to the weights and biases and it's done\n",
    "    \n",
    "    It takes as input the network and the label of the number the network was activated on\n",
    "    \n",
    "    It returns the modifications to the weights and biases (nablaW and nablaB) \n",
    "    the network should have\n",
    "    \"\"\"\n",
    "    layers = net.layers\n",
    "    nablaB = [np.zeros(i.shape) for i in net.b]\n",
    "    nablaW = [np.zeros(i.shape) for i in net.w]\n",
    "    delta = np.zeros(net.layers[-1])\n",
    "    \n",
    "    negSamples = np.random.randint(len(table), size=nNegSamples)\n",
    "    negSamplesPos = []\n",
    "    for i in negSamples:\n",
    "        # finding the int representation of the word and the position on the oneHotVec\n",
    "        negSamples.append(SIdic[table[i]])\n",
    "    \n",
    "    correctWord = argmax(y)\n",
    "    \n",
    "    # if the correct word was chosen, it removes from the negative samples\n",
    "    if correctWord in negSamples:\n",
    "        negSamples = np.delete(negSamples, np.where(negSamples == correctWord))\n",
    "\n",
    "    delta[correctWord] += (net.a[-1][correctWord] - 1)    \n",
    "    for sample in negSamples:\n",
    "        delta[sample] += (net.a[-1][sample] - 0)\n",
    "    \n",
    "    for l in range(net.nLayers-1, 0, -1):\n",
    "        #nablaB and nablaW have -1 because they only have 2 layers instead of 3\n",
    "        nablaB[l-1] = delta\n",
    "                \n",
    "        # if its the last layer, it'll only update the negativeSamples and the correctOutput\n",
    "        if l == net.nLayers-1:\n",
    "            for j in negSamples:\n",
    "                for k in range(layers[l-1]):\n",
    "                    nablaW[l-1][k][j] += net.a[l-1][k]*delta[j]\n",
    "            for k in range(layers[l-1]):\n",
    "                nablaW[l-1][k][correctWord] += net.a[l-1][k]*delta[correctWord]\n",
    "        \n",
    "        else:\n",
    "            for j in range(layers[l]):\n",
    "                for k in range(layers[l-1]):\n",
    "                    nablaW[l-1][k][j] += net.a[l-1][k]*delta[j]\n",
    "        \n",
    "        # finding the error one layer behind\n",
    "        # in the book it needs a transpose because its weight[layer][receivingNeuron][givingNeuron]\n",
    "        # but my implementation uses weight[layer][givingNeuron][receivingNeuron] so it's not necessary\n",
    "        delta = (np.dot(net.w[l-1], delta))*sigmoid_derivative(net.z[l-1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    for l in range(net.nLayers-1, 0, -1):\n",
    "        #nablaB and nablaW have -1 because they only have 2 layers instead of 3\n",
    "        nablaB[l-1] = delta\n",
    "                \n",
    "        for j in range(layers[l]):\n",
    "            for k in range(layers[l-1]):\n",
    "                nablaW[l-1][k][j] += net.a[l-1][k]*delta[j]\n",
    "        \n",
    "        # finding the error one layer behind\n",
    "        # in the book it needs a transpose because its weight[layer][receivingNeuron][givingNeuron]\n",
    "        # but my implementation uses weight[layer][givingNeuron][receivingNeuron] so it's not necessary\n",
    "        delta = (np.dot(net.w[l-1], delta))*sigmoid_derivative(net.z[l-1])\n",
    "        \n",
    "    return nablaB, nablaW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8536b0c8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def SGD(net: Network, X: list, y: list, nNegSamples, table, batchSize: int, nEpochs: int, \n",
    "        learningRate, lamb, earlyStop=False) -> Network:\n",
    "    \"\"\"\n",
    "    Implementation of Stochastic Gradient Descent\n",
    "    \n",
    "    It takes as input the network, the MNIST dataset, the MNIST labels of the dataset, \n",
    "    the size of the batch to do gradient descent, the number of epochs it should run,\n",
    "    the learning rate eta (I found the best eta to be in the order of 1s)\n",
    "    and the regularization term lambda\n",
    "    \n",
    "    It returns a trained network\n",
    "    \"\"\"\n",
    "    bestAcc = 0\n",
    "    bestEpoch = 0\n",
    "    earlyNet = net\n",
    "    eta = learningRate\n",
    "    etaChangeEpoch = 0\n",
    "    for epoch in range(nEpochs):\n",
    "        batch = rd.sample(range(len(X)), batchSize)\n",
    "        nablaB = [np.zeros(i.shape) for i in net.b]\n",
    "        nablaW = [np.zeros(i.shape) for i in net.w]\n",
    "        for i in batch:\n",
    "            net = setInput(net, X[i])\n",
    "            # finding what should be modified based on this particular example\n",
    "            deltaNablaB, deltaNablaW = backProp(net, y[i], nNegSamples, table)\n",
    "            # passing this modifications to our overall modifications matrices\n",
    "            for l in range(net.nLayers-1):\n",
    "                nablaB[l] += deltaNablaB[l]\n",
    "                nablaW[l] += deltaNablaW[l]\n",
    "        \n",
    "        # applying the changes to our network\n",
    "        for l in range(net.nLayers-1):\n",
    "            net.b[l] = net.b[l] - eta * (nablaB[l]/batchSize) \n",
    "            net.w[l] = net.w[l] - eta * (nablaW[l]/batchSize) - eta * (lamb/batchSize) *  net.w[l]\n",
    "        acc, outputs = testNetwork(net, X, y, nTests=batchSize)\n",
    "        if acc > bestAcc:\n",
    "            bestAcc = acc\n",
    "            bestEpoch = epoch\n",
    "            earlyNet = Network.copy(net)\n",
    "            etaChangeEpoch = epoch\n",
    "        print(f'learningRate: {learningRate} epochs: {epoch} acc: {acc}, outputs: {outputs}')\n",
    "    print(f'best acc: {bestAcc} on epoch: {bestEpoch}')\n",
    "    if earlyStop:\n",
    "        return earlyNet\n",
    "    return net\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5918a0e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learningRate: 2 epochs: 0 acc: 0.06, outputs: [  0.   0. 100.   0.   0.   0.   0.   0.   0.   0.]\n",
      "learningRate: 2 epochs: 1 acc: 0.08, outputs: [  0.   0.   0.   0.   0.   0.   0.   0. 100.   0.]\n",
      "learningRate: 2 epochs: 2 acc: 0.06, outputs: [  0.   0. 100.   0.   0.   0.   0.   0.   0.   0.]\n",
      "learningRate: 2 epochs: 3 acc: 0.11, outputs: [ 0.  0.  0.  0.  3.  0.  0. 97.  0.  0.]\n",
      "learningRate: 2 epochs: 4 acc: 0.2, outputs: [ 0.  0.  0.  0. 38.  0.  1.  4. 57.  0.]\n",
      "learningRate: 2 epochs: 5 acc: 0.18, outputs: [94.  0.  0.  0.  0.  0.  6.  0.  0.  0.]\n",
      "learningRate: 2 epochs: 6 acc: 0.19, outputs: [ 0. 14.  0.  1.  0.  0.  0. 85.  0.  0.]\n",
      "learningRate: 2 epochs: 7 acc: 0.08, outputs: [  0.   0.   0.   0.   0.   0.   0.   0. 100.   0.]\n",
      "learningRate: 2 epochs: 8 acc: 0.39, outputs: [39. 12.  0.  0.  0.  0.  9. 40.  0.  0.]\n",
      "learningRate: 2 epochs: 9 acc: 0.39, outputs: [12. 41.  0.  0. 16. 16. 12.  0.  0.  3.]\n",
      "learningRate: 2 epochs: 10 acc: 0.36, outputs: [19. 45.  0.  0.  0.  0.  0. 31.  1.  4.]\n",
      "learningRate: 2 epochs: 11 acc: 0.42, outputs: [32. 37.  0.  0.  0.  0.  9. 22.  0.  0.]\n",
      "learningRate: 2 epochs: 12 acc: 0.36, outputs: [21. 29.  0.  0. 24. 26.  0.  0.  0.  0.]\n",
      "learningRate: 2 epochs: 13 acc: 0.54, outputs: [27. 17.  0.  0.  0.  0. 10. 14. 16. 16.]\n",
      "learningRate: 2 epochs: 14 acc: 0.38, outputs: [16. 15. 41.  0. 28.  0.  0.  0.  0.  0.]\n",
      "learningRate: 2 epochs: 15 acc: 0.5, outputs: [ 8. 23.  0. 22. 28.  0. 19.  0.  0.  0.]\n",
      "learningRate: 2 epochs: 16 acc: 0.46, outputs: [11. 20.  8. 11.  0.  5.  0. 41.  0.  4.]\n",
      "learningRate: 2 epochs: 17 acc: 0.44, outputs: [37. 27.  0.  0. 23.  0. 12.  0.  1.  0.]\n",
      "learningRate: 2 epochs: 18 acc: 0.41, outputs: [ 0. 21.  2. 25. 43.  0.  9.  0.  0.  0.]\n",
      "learningRate: 2 epochs: 19 acc: 0.37, outputs: [ 0. 23.  0.  0.  6. 50.  7. 14.  0.  0.]\n",
      "learningRate: 2 epochs: 20 acc: 0.59, outputs: [14.  7.  1. 10.  4.  0. 10. 31. 23.  0.]\n",
      "learningRate: 2 epochs: 21 acc: 0.66, outputs: [22. 14. 19.  4.  9.  0. 15.  9.  1.  7.]\n",
      "learningRate: 2 epochs: 22 acc: 0.54, outputs: [25. 15.  0.  1.  3.  0.  8. 38. 10.  0.]\n",
      "learningRate: 2 epochs: 23 acc: 0.44, outputs: [ 0. 34.  0. 32.  5.  0. 10.  0.  0. 19.]\n",
      "learningRate: 2 epochs: 24 acc: 0.46, outputs: [30. 15.  8.  0.  1.  0.  2. 10.  0. 34.]\n",
      "learningRate: 2 epochs: 25 acc: 0.53, outputs: [10. 14.  0.  0.  0.  0. 12.  7. 41. 16.]\n",
      "learningRate: 2 epochs: 26 acc: 0.44, outputs: [35. 17.  0.  0. 41.  0.  6.  1.  0.  0.]\n",
      "learningRate: 2 epochs: 27 acc: 0.55, outputs: [ 2. 22. 16. 26.  0.  0.  9.  9.  0. 16.]\n",
      "learningRate: 2 epochs: 28 acc: 0.68, outputs: [18. 11.  3. 12.  8.  0. 12. 21.  9.  6.]\n",
      "learningRate: 2 epochs: 29 acc: 0.61, outputs: [12. 12. 28.  6. 22.  1.  8.  9.  2.  0.]\n",
      "learningRate: 2 epochs: 30 acc: 0.66, outputs: [12. 12.  2. 10.  6. 14. 19. 16.  0.  9.]\n",
      "learningRate: 2 epochs: 31 acc: 0.73, outputs: [12. 14. 11. 17. 18.  2.  9. 10.  7.  0.]\n",
      "learningRate: 2 epochs: 32 acc: 0.68, outputs: [12. 15.  0.  4.  7.  0. 11. 15. 29.  7.]\n",
      "learningRate: 2 epochs: 33 acc: 0.67, outputs: [14. 13.  2. 29.  8.  6. 10. 18.  0.  0.]\n",
      "learningRate: 2 epochs: 34 acc: 0.62, outputs: [12. 20.  8.  0. 18.  0. 13. 12. 11.  6.]\n",
      "learningRate: 2 epochs: 35 acc: 0.73, outputs: [13. 18.  1. 19.  7.  2. 11. 16. 12.  1.]\n",
      "learningRate: 2 epochs: 36 acc: 0.65, outputs: [11. 12. 23.  4. 12.  3. 12.  5.  1. 17.]\n",
      "learningRate: 2 epochs: 37 acc: 0.71, outputs: [20. 20.  1.  6.  6.  3. 15. 14.  8.  7.]\n",
      "learningRate: 2 epochs: 38 acc: 0.73, outputs: [10. 12.  0. 18.  7.  0. 12. 12. 15. 14.]\n",
      "learningRate: 2 epochs: 39 acc: 0.72, outputs: [14. 16. 12. 11. 16.  6. 14. 10.  1.  0.]\n",
      "learningRate: 2 epochs: 40 acc: 0.69, outputs: [10. 15.  6. 21.  7.  0. 12. 22.  3.  4.]\n",
      "learningRate: 2 epochs: 41 acc: 0.83, outputs: [13. 13. 12. 12. 11.  0. 12. 12.  9.  6.]\n",
      "learningRate: 2 epochs: 42 acc: 0.78, outputs: [14. 15.  5. 11.  8.  2. 13. 23.  7.  2.]\n",
      "learningRate: 2 epochs: 43 acc: 0.75, outputs: [12. 15.  8. 21. 17.  0. 11. 10.  5.  1.]\n",
      "learningRate: 2 epochs: 44 acc: 0.74, outputs: [14. 13.  7.  3. 12. 14. 12. 17.  4.  4.]\n",
      "learningRate: 2 epochs: 45 acc: 0.83, outputs: [12. 13.  8.  9.  7.  7. 13. 10.  7. 14.]\n",
      "learningRate: 2 epochs: 46 acc: 0.83, outputs: [14. 12.  8. 14. 13.  4. 12. 14.  6.  3.]\n",
      "learningRate: 2 epochs: 47 acc: 0.8, outputs: [12. 13.  3. 16.  6.  1. 13. 10. 13. 13.]\n",
      "learningRate: 2 epochs: 48 acc: 0.81, outputs: [12. 13.  2. 11.  9. 10. 12. 14. 10.  7.]\n",
      "learningRate: 2 epochs: 49 acc: 0.77, outputs: [14. 12.  4. 20.  8.  0. 15. 13.  5.  9.]\n",
      "learningRate: 2 epochs: 50 acc: 0.82, outputs: [12. 14.  2. 15. 12.  2. 12. 13. 14.  4.]\n",
      "learningRate: 2 epochs: 51 acc: 0.76, outputs: [14. 21.  3. 17.  9.  2. 12. 15.  1.  6.]\n",
      "learningRate: 2 epochs: 52 acc: 0.82, outputs: [14. 17.  7. 13. 16.  2. 12.  9.  7.  3.]\n",
      "learningRate: 2 epochs: 53 acc: 0.84, outputs: [14. 13.  2. 15.  8.  4. 13. 12.  9. 10.]\n",
      "learningRate: 2 epochs: 54 acc: 0.81, outputs: [14. 13.  8. 13. 12.  3. 13. 17.  7.  0.]\n",
      "learningRate: 2 epochs: 55 acc: 0.82, outputs: [14. 13.  5. 16.  8.  3. 12. 10.  4. 15.]\n",
      "learningRate: 2 epochs: 56 acc: 0.81, outputs: [14. 15.  4. 17. 16.  3. 12. 11.  7.  1.]\n",
      "learningRate: 2 epochs: 57 acc: 0.87, outputs: [14. 13.  4. 16.  9.  3. 12. 14.  7.  8.]\n",
      "learningRate: 2 epochs: 58 acc: 0.84, outputs: [12. 13.  7.  7. 12. 12. 12. 13.  7.  5.]\n",
      "learningRate: 2 epochs: 59 acc: 0.89, outputs: [14. 13.  5. 15. 10.  3. 12. 14.  7.  7.]\n",
      "learningRate: 2 epochs: 60 acc: 0.86, outputs: [13. 13.  4.  9.  9.  7. 12. 12. 10. 11.]\n",
      "learningRate: 2 epochs: 61 acc: 0.83, outputs: [14. 12.  7. 13. 13.  3. 12. 18.  8.  0.]\n",
      "learningRate: 2 epochs: 62 acc: 0.83, outputs: [11. 13.  2. 14.  8.  7. 12. 10. 10. 13.]\n",
      "learningRate: 2 epochs: 63 acc: 0.79, outputs: [14. 13.  8. 15. 16.  3. 13. 12.  6.  0.]\n",
      "learningRate: 2 epochs: 64 acc: 0.82, outputs: [13. 13.  2. 18.  9.  1. 11. 12. 13.  8.]\n",
      "learningRate: 2 epochs: 65 acc: 0.85, outputs: [14. 12.  8. 11. 12.  4. 12. 16.  7.  4.]\n",
      "learningRate: 2 epochs: 66 acc: 0.79, outputs: [11. 12.  4. 24.  7.  2. 11. 11.  7. 11.]\n",
      "learningRate: 2 epochs: 67 acc: 0.88, outputs: [14. 14.  6.  9. 14.  6. 12. 12.  7.  6.]\n",
      "learningRate: 2 epochs: 68 acc: 0.81, outputs: [13. 12. 10. 16.  8.  4. 11. 16.  6.  4.]\n",
      "learningRate: 2 epochs: 69 acc: 0.87, outputs: [13. 14.  5. 11.  7.  7. 13. 12.  7. 11.]\n",
      "learningRate: 2 epochs: 70 acc: 0.81, outputs: [14. 14.  9. 14. 15.  3. 11. 13.  6.  1.]\n",
      "learningRate: 2 epochs: 71 acc: 0.85, outputs: [13. 13.  2. 15.  8.  6. 12. 11.  8. 12.]\n",
      "learningRate: 2 epochs: 72 acc: 0.85, outputs: [14. 12.  7. 12. 18.  4. 12. 11.  8.  2.]\n",
      "learningRate: 2 epochs: 73 acc: 0.86, outputs: [14. 13.  6. 12.  7.  6. 12. 12.  8. 10.]\n",
      "learningRate: 2 epochs: 74 acc: 0.87, outputs: [15. 12.  7. 13. 11.  4. 12. 12.  7.  7.]\n",
      "learningRate: 2 epochs: 75 acc: 0.84, outputs: [14. 14.  6. 11. 18.  4. 12. 12.  8.  1.]\n",
      "learningRate: 2 epochs: 76 acc: 0.89, outputs: [13. 13.  5. 12. 12.  7. 12. 12.  8.  6.]\n",
      "learningRate: 2 epochs: 77 acc: 0.87, outputs: [15. 15.  6. 13. 11.  3. 12. 12.  7.  6.]\n",
      "learningRate: 2 epochs: 78 acc: 0.88, outputs: [14. 14.  3. 11. 12.  4. 12. 11. 11.  8.]\n",
      "learningRate: 2 epochs: 79 acc: 0.87, outputs: [14. 13.  5. 12. 18.  6. 12. 11.  8.  1.]\n",
      "learningRate: 2 epochs: 80 acc: 0.88, outputs: [15. 13.  7. 12.  8.  4. 12. 11.  8. 10.]\n",
      "learningRate: 2 epochs: 81 acc: 0.89, outputs: [14. 12.  6. 12. 15.  5. 12. 11.  8.  5.]\n",
      "learningRate: 2 epochs: 82 acc: 0.9, outputs: [14. 16.  5. 11. 12.  4. 12. 11.  8.  7.]\n",
      "learningRate: 2 epochs: 83 acc: 0.85, outputs: [15. 12.  8. 13. 13.  4. 12. 12.  6.  5.]\n",
      "learningRate: 2 epochs: 84 acc: 0.89, outputs: [13. 12.  5. 13. 11.  7. 12. 12.  7.  8.]\n",
      "learningRate: 2 epochs: 85 acc: 0.82, outputs: [15. 12.  8. 13. 12.  4. 12. 17.  6.  1.]\n",
      "learningRate: 2 epochs: 86 acc: 0.88, outputs: [11. 12.  2. 12. 11.  9. 13. 11. 10.  9.]\n",
      "learningRate: 2 epochs: 87 acc: 0.86, outputs: [15. 13.  8. 16. 11.  2. 11. 11.  7.  6.]\n",
      "learningRate: 2 epochs: 88 acc: 0.92, outputs: [14. 13.  4. 13. 11.  5. 12. 11.  8.  9.]\n",
      "learningRate: 2 epochs: 89 acc: 0.89, outputs: [14. 13.  7. 12. 12.  4. 12. 12.  8.  6.]\n",
      "learningRate: 2 epochs: 90 acc: 0.88, outputs: [13. 14.  4. 15. 12.  8. 10. 10.  7.  7.]\n",
      "learningRate: 2 epochs: 91 acc: 0.89, outputs: [13. 12.  7. 11. 11.  4. 12. 14.  9.  7.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learningRate: 2 epochs: 92 acc: 0.89, outputs: [12. 14.  4. 15. 10.  6. 12. 10.  9.  8.]\n",
      "learningRate: 2 epochs: 93 acc: 0.91, outputs: [14. 13.  6. 13. 11.  4. 12. 13.  7.  7.]\n",
      "learningRate: 2 epochs: 94 acc: 0.9, outputs: [14. 12.  4. 14. 10.  7. 13. 10.  7.  9.]\n",
      "learningRate: 2 epochs: 95 acc: 0.9, outputs: [14. 15.  6. 14. 11.  4. 12. 10.  6.  8.]\n",
      "learningRate: 2 epochs: 96 acc: 0.87, outputs: [14. 12.  6. 14.  8.  5. 11. 10.  9. 11.]\n",
      "learningRate: 2 epochs: 97 acc: 0.91, outputs: [12. 15.  5. 11. 12.  6. 12. 11.  9.  7.]\n",
      "learningRate: 2 epochs: 98 acc: 0.91, outputs: [12. 13.  6. 12. 11.  5. 12. 11. 10.  8.]\n",
      "learningRate: 2 epochs: 99 acc: 0.91, outputs: [14. 14.  4. 13. 11.  6. 12. 12.  7.  7.]\n",
      "learningRate: 2 epochs: 100 acc: 0.92, outputs: [14. 13.  6. 12. 11.  5. 12. 11.  8.  8.]\n",
      "learningRate: 2 epochs: 101 acc: 0.91, outputs: [13. 14.  5. 12. 11.  5. 12. 12.  9.  7.]\n",
      "learningRate: 2 epochs: 102 acc: 0.93, outputs: [14. 12.  6. 12. 11.  5. 12. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 103 acc: 0.87, outputs: [14. 12.  5. 13. 13.  6. 12. 15.  7.  3.]\n",
      "learningRate: 2 epochs: 104 acc: 0.88, outputs: [12. 12.  5. 12. 11.  3. 11. 11. 14.  9.]\n",
      "learningRate: 2 epochs: 105 acc: 0.84, outputs: [14. 12.  8. 13. 12.  4. 11. 18.  6.  2.]\n",
      "learningRate: 2 epochs: 106 acc: 0.9, outputs: [13. 13.  3. 14. 11.  7. 12. 11.  7.  9.]\n",
      "learningRate: 2 epochs: 107 acc: 0.92, outputs: [14. 15.  5. 12. 10.  5. 12. 11.  8.  8.]\n",
      "learningRate: 2 epochs: 108 acc: 0.89, outputs: [14. 12.  4. 15. 12.  5. 12. 13.  7.  6.]\n",
      "learningRate: 2 epochs: 109 acc: 0.9, outputs: [14. 12.  6. 12.  8.  5. 13. 12.  8. 10.]\n",
      "learningRate: 2 epochs: 110 acc: 0.9, outputs: [12. 13.  5. 14. 10.  5. 12.  9. 10. 10.]\n",
      "learningRate: 2 epochs: 111 acc: 0.94, outputs: [14. 14.  5. 11. 11.  6. 12. 11.  8.  8.]\n",
      "learningRate: 2 epochs: 112 acc: 0.91, outputs: [15. 13.  6. 12. 10.  5. 12. 11.  8.  8.]\n",
      "learningRate: 2 epochs: 113 acc: 0.89, outputs: [12. 12.  5. 13. 10.  5. 12. 11. 10. 10.]\n",
      "learningRate: 2 epochs: 114 acc: 0.91, outputs: [13. 15.  5. 15. 11.  5. 12. 10.  6.  8.]\n",
      "learningRate: 2 epochs: 115 acc: 0.93, outputs: [14. 12.  5. 11. 11.  6. 12. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 116 acc: 0.9, outputs: [13. 13.  6. 13. 11.  5. 12. 11.  8.  8.]\n",
      "learningRate: 2 epochs: 117 acc: 0.92, outputs: [12. 12.  6. 11. 11.  6. 11. 10. 12.  9.]\n",
      "learningRate: 2 epochs: 118 acc: 0.9, outputs: [14. 13.  7. 13. 11.  5. 12. 11.  6.  8.]\n",
      "learningRate: 2 epochs: 119 acc: 0.94, outputs: [13. 14.  5. 11. 11.  6. 12. 10.  9.  9.]\n",
      "learningRate: 2 epochs: 120 acc: 0.93, outputs: [13. 12.  6. 11. 11.  6. 12. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 121 acc: 0.93, outputs: [13. 12.  6. 11. 11.  6. 12. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 122 acc: 0.92, outputs: [12. 12.  7. 12. 11.  5. 12. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 123 acc: 0.95, outputs: [14. 13.  5. 11. 11.  6. 12. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 124 acc: 0.93, outputs: [13. 12.  6. 11. 11.  6. 12. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 125 acc: 0.93, outputs: [14. 13.  4. 13. 11.  6. 12. 12.  7.  8.]\n",
      "learningRate: 2 epochs: 126 acc: 0.91, outputs: [12. 14.  5. 12. 10.  5. 11. 10. 12.  9.]\n",
      "learningRate: 2 epochs: 127 acc: 0.9, outputs: [13. 14.  5. 12. 12.  8. 11. 12.  7.  6.]\n",
      "learningRate: 2 epochs: 128 acc: 0.92, outputs: [13. 14.  5. 13. 11.  5. 12. 10.  9.  8.]\n",
      "learningRate: 2 epochs: 129 acc: 0.9, outputs: [14. 13.  5. 11. 16.  6. 12. 11.  8.  4.]\n",
      "learningRate: 2 epochs: 130 acc: 0.87, outputs: [15. 12.  7. 13.  7.  4. 12. 12.  7. 11.]\n",
      "learningRate: 2 epochs: 131 acc: 0.87, outputs: [12. 12.  6. 11. 16.  9. 11. 12.  8.  3.]\n",
      "learningRate: 2 epochs: 132 acc: 0.89, outputs: [12. 13.  8. 12. 10.  4. 11. 11. 10.  9.]\n",
      "learningRate: 2 epochs: 133 acc: 0.93, outputs: [14. 12.  6. 11. 12.  6. 12. 12.  8.  7.]\n",
      "learningRate: 2 epochs: 134 acc: 0.88, outputs: [12. 13.  5. 16. 10.  6. 11. 13.  7.  7.]\n",
      "learningRate: 2 epochs: 135 acc: 0.9, outputs: [12. 12.  7. 12. 11.  5. 10. 11. 12.  8.]\n",
      "learningRate: 2 epochs: 136 acc: 0.89, outputs: [14. 12.  5. 13. 12.  6. 11. 15.  7.  5.]\n",
      "learningRate: 2 epochs: 137 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 12. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 138 acc: 0.93, outputs: [14. 13.  6. 11. 10.  6. 12. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 139 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 12. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 140 acc: 0.92, outputs: [14. 12.  6. 11. 10.  8. 11. 13.  8.  7.]\n",
      "learningRate: 2 epochs: 141 acc: 0.9, outputs: [10. 13.  5. 14. 10.  5. 12. 12. 10.  9.]\n",
      "learningRate: 2 epochs: 142 acc: 0.91, outputs: [13. 12.  6. 10. 12.  6. 13. 12.  9.  7.]\n",
      "learningRate: 2 epochs: 143 acc: 0.9, outputs: [12. 12.  5. 13. 10.  5. 12. 12. 10.  9.]\n",
      "learningRate: 2 epochs: 144 acc: 0.91, outputs: [13. 12.  5. 12. 12.  7. 12. 12.  8.  7.]\n",
      "learningRate: 2 epochs: 145 acc: 0.92, outputs: [14. 12.  7. 12. 11.  4. 12. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 146 acc: 0.91, outputs: [14. 13.  4. 14. 10.  5. 12. 12.  7.  9.]\n",
      "learningRate: 2 epochs: 147 acc: 0.92, outputs: [12. 12.  5. 11. 11.  6. 12. 12. 11.  8.]\n",
      "learningRate: 2 epochs: 148 acc: 0.91, outputs: [13. 12.  5. 12. 10.  8. 11. 12.  8.  9.]\n",
      "learningRate: 2 epochs: 149 acc: 0.88, outputs: [12. 15.  6. 11. 11.  4. 12. 11. 11.  7.]\n",
      "learningRate: 2 epochs: 150 acc: 0.89, outputs: [14. 15.  5. 14. 11.  5. 11. 11.  7.  7.]\n",
      "learningRate: 2 epochs: 151 acc: 0.91, outputs: [12. 12.  5. 11. 10.  6. 12. 12. 11.  9.]\n",
      "learningRate: 2 epochs: 152 acc: 0.91, outputs: [12. 12.  7. 12. 10.  5. 11. 12. 10.  9.]\n",
      "learningRate: 2 epochs: 153 acc: 0.91, outputs: [14. 13.  7. 12. 10.  5. 11. 13.  8.  7.]\n",
      "learningRate: 2 epochs: 154 acc: 0.93, outputs: [14. 13.  7. 11. 10.  6. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 155 acc: 0.93, outputs: [14. 12.  6. 11. 12.  6. 12. 12.  8.  7.]\n",
      "learningRate: 2 epochs: 156 acc: 0.93, outputs: [14. 12.  6. 11. 10.  6. 12. 12.  8.  9.]\n",
      "learningRate: 2 epochs: 157 acc: 0.92, outputs: [14. 12.  7. 12. 12.  5. 11. 12.  8.  7.]\n",
      "learningRate: 2 epochs: 158 acc: 0.92, outputs: [14. 13.  2. 13. 11.  6. 12. 10.  8. 11.]\n",
      "learningRate: 2 epochs: 159 acc: 0.91, outputs: [14. 13.  7. 12. 12.  5. 11. 11.  8.  7.]\n",
      "learningRate: 2 epochs: 160 acc: 0.94, outputs: [14. 13.  4. 12. 11.  6. 12. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 161 acc: 0.89, outputs: [12. 12.  7. 12. 14.  5. 11. 12. 10.  5.]\n",
      "learningRate: 2 epochs: 162 acc: 0.9, outputs: [12. 12.  6. 11.  8.  6. 12. 12. 10. 11.]\n",
      "learningRate: 2 epochs: 163 acc: 0.93, outputs: [14. 13.  6. 11. 11.  6. 12. 11.  8.  8.]\n",
      "learningRate: 2 epochs: 164 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 12. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 165 acc: 0.89, outputs: [11. 12.  5. 18. 11.  5. 11. 11.  8.  8.]\n",
      "learningRate: 2 epochs: 166 acc: 0.92, outputs: [14. 12.  6. 10. 12.  7. 12. 12.  8.  7.]\n",
      "learningRate: 2 epochs: 167 acc: 0.93, outputs: [13. 12.  7. 12. 11.  5. 11. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 168 acc: 0.91, outputs: [15. 12.  7. 13. 10.  5. 11. 12.  7.  8.]\n",
      "learningRate: 2 epochs: 169 acc: 0.9, outputs: [13. 13.  5. 13. 12.  5. 12. 11.  9.  7.]\n",
      "learningRate: 2 epochs: 170 acc: 0.92, outputs: [13. 13.  6. 12. 11.  5. 12. 11.  9.  8.]\n",
      "learningRate: 2 epochs: 171 acc: 0.92, outputs: [14. 13.  7. 12. 11.  5. 11. 11.  8.  8.]\n",
      "learningRate: 2 epochs: 172 acc: 0.89, outputs: [13. 12.  7. 12. 15.  5. 11. 11.  9.  5.]\n",
      "learningRate: 2 epochs: 173 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 12. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 174 acc: 0.9, outputs: [14. 13.  5. 14. 11.  5. 11. 12.  7.  8.]\n",
      "learningRate: 2 epochs: 175 acc: 0.92, outputs: [14. 13.  7. 12. 11.  5. 11. 11.  8.  8.]\n",
      "learningRate: 2 epochs: 176 acc: 0.92, outputs: [13. 13.  7. 12. 11.  5. 11. 11.  9.  8.]\n",
      "learningRate: 2 epochs: 177 acc: 0.91, outputs: [14. 13.  7. 13. 11.  5. 11. 11.  7.  8.]\n",
      "learningRate: 2 epochs: 178 acc: 0.9, outputs: [14. 13.  6. 15. 11.  5. 11. 10.  7.  8.]\n",
      "learningRate: 2 epochs: 179 acc: 0.93, outputs: [14. 13.  6. 11. 11.  6. 12. 11.  8.  8.]\n",
      "learningRate: 2 epochs: 180 acc: 0.93, outputs: [14. 12.  7. 12. 11.  5. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 181 acc: 0.92, outputs: [14. 12.  7. 13. 11.  5. 11. 12.  7.  8.]\n",
      "learningRate: 2 epochs: 182 acc: 0.9, outputs: [12. 12.  6. 11. 11.  6. 10. 11. 13.  8.]\n",
      "learningRate: 2 epochs: 183 acc: 0.92, outputs: [14. 12.  7. 13. 11.  5. 11. 12.  7.  8.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learningRate: 2 epochs: 184 acc: 0.94, outputs: [14. 13.  7. 11. 11.  6. 11. 10.  8.  9.]\n",
      "learningRate: 2 epochs: 185 acc: 0.93, outputs: [13. 12.  6. 11. 10.  6. 12. 12.  9.  9.]\n",
      "learningRate: 2 epochs: 186 acc: 0.92, outputs: [14. 13.  7. 12. 11.  5. 11. 11.  8.  8.]\n",
      "learningRate: 2 epochs: 187 acc: 0.91, outputs: [14. 12.  5. 14. 11.  5. 11. 13.  7.  8.]\n",
      "learningRate: 2 epochs: 188 acc: 0.93, outputs: [13. 12.  6. 12. 11.  5. 11. 11. 10.  9.]\n",
      "learningRate: 2 epochs: 189 acc: 0.91, outputs: [14. 12.  6. 14. 11.  5. 11. 12.  7.  8.]\n",
      "learningRate: 2 epochs: 190 acc: 0.93, outputs: [14. 12.  6. 13. 11.  5. 11. 11.  8.  9.]\n",
      "learningRate: 2 epochs: 191 acc: 0.93, outputs: [14. 12.  5. 12. 11.  6. 12. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 192 acc: 0.92, outputs: [14. 12.  6. 13. 11.  5. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 193 acc: 0.94, outputs: [13. 12.  7. 11. 11.  6. 11. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 194 acc: 0.93, outputs: [14. 12.  5. 12. 11.  6. 12. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 195 acc: 0.93, outputs: [13. 12.  7. 12. 11.  5. 11. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 196 acc: 0.94, outputs: [14. 12.  7. 11. 11.  6. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 197 acc: 0.92, outputs: [14. 12.  5. 13. 11.  5. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 198 acc: 0.91, outputs: [14. 12.  6. 14. 11.  5. 11. 12.  7.  8.]\n",
      "learningRate: 2 epochs: 199 acc: 0.94, outputs: [13. 12.  7. 11. 11.  6. 11. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 200 acc: 0.92, outputs: [14. 12.  7. 14. 11.  4. 11. 12.  7.  8.]\n",
      "learningRate: 2 epochs: 201 acc: 0.94, outputs: [14. 13.  4. 12. 11.  6. 12. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 202 acc: 0.94, outputs: [14. 12.  7. 11. 11.  6. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 203 acc: 0.92, outputs: [13. 12.  6. 13. 11.  5. 11. 10.  9. 10.]\n",
      "learningRate: 2 epochs: 204 acc: 0.92, outputs: [14. 12.  6. 13. 11.  5. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 205 acc: 0.92, outputs: [13. 12.  5. 14. 11.  7. 11. 12.  7.  8.]\n",
      "learningRate: 2 epochs: 206 acc: 0.93, outputs: [14. 12.  7. 12. 11.  5. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 207 acc: 0.92, outputs: [14. 12.  6. 13. 11.  5. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 208 acc: 0.93, outputs: [14. 12.  7. 12. 11.  5. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 209 acc: 0.92, outputs: [13. 13.  7. 12. 11.  5. 11. 11.  9.  8.]\n",
      "learningRate: 2 epochs: 210 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 12. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 211 acc: 0.93, outputs: [13. 13.  7. 13. 11.  5. 11. 10.  8.  9.]\n",
      "learningRate: 2 epochs: 212 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 213 acc: 0.92, outputs: [12. 12.  6. 12. 11.  6. 11. 12. 10.  8.]\n",
      "learningRate: 2 epochs: 214 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 12. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 215 acc: 0.94, outputs: [14. 12.  7. 11. 11.  6. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 216 acc: 0.93, outputs: [14. 13.  6. 11. 11.  6. 12. 11.  8.  8.]\n",
      "learningRate: 2 epochs: 217 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 218 acc: 0.94, outputs: [14. 13.  7. 11. 11.  6. 11. 10.  8.  9.]\n",
      "learningRate: 2 epochs: 219 acc: 0.93, outputs: [14. 12.  7. 12. 11.  5. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 220 acc: 0.92, outputs: [14. 12.  5. 13. 11.  6. 11.  9.  8. 11.]\n",
      "learningRate: 2 epochs: 221 acc: 0.88, outputs: [14. 12.  7. 12. 16.  5. 11. 11.  8.  4.]\n",
      "learningRate: 2 epochs: 222 acc: 0.94, outputs: [14. 13.  4. 12. 11.  6. 12. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 223 acc: 0.92, outputs: [14. 12.  5. 13. 11.  5. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 224 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 225 acc: 0.94, outputs: [14. 13.  6. 11. 11.  6. 12. 10.  8.  9.]\n",
      "learningRate: 2 epochs: 226 acc: 0.94, outputs: [13. 12.  6. 11. 11.  8. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 227 acc: 0.93, outputs: [14. 12.  6. 13. 11.  5. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 228 acc: 0.94, outputs: [14. 12.  6. 11. 11.  7. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 229 acc: 0.93, outputs: [14. 12.  6. 13. 11.  5. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 230 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 12. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 231 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 232 acc: 0.93, outputs: [13. 12.  4. 13. 11.  8. 11. 11.  8.  9.]\n",
      "learningRate: 2 epochs: 233 acc: 0.94, outputs: [14. 12.  6. 11. 11.  7. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 234 acc: 0.93, outputs: [14. 13.  7. 11. 11.  6. 11. 11.  8.  8.]\n",
      "learningRate: 2 epochs: 235 acc: 0.93, outputs: [14. 13.  6. 11. 11.  6. 12. 11.  8.  8.]\n",
      "learningRate: 2 epochs: 236 acc: 0.91, outputs: [14. 12.  5. 15. 11.  5. 11. 12.  7.  8.]\n",
      "learningRate: 2 epochs: 237 acc: 0.94, outputs: [14. 13.  6. 11. 11.  6. 12. 10.  8.  9.]\n",
      "learningRate: 2 epochs: 238 acc: 0.93, outputs: [14. 13.  6. 13. 11.  5. 11. 10.  8.  9.]\n",
      "learningRate: 2 epochs: 239 acc: 0.93, outputs: [14. 12.  6. 12. 11.  5. 12. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 240 acc: 0.94, outputs: [12. 12.  6. 11. 11.  6. 12. 11. 10.  9.]\n",
      "learningRate: 2 epochs: 241 acc: 0.93, outputs: [14. 12.  6. 12. 11.  5. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 242 acc: 0.93, outputs: [12. 13.  6. 11. 11.  6. 12. 10. 10.  9.]\n",
      "learningRate: 2 epochs: 243 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 12. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 244 acc: 0.93, outputs: [12. 12.  6. 11. 11.  8. 11. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 245 acc: 0.92, outputs: [14. 12.  6. 11. 12.  6. 12. 13.  8.  6.]\n",
      "learningRate: 2 epochs: 246 acc: 0.92, outputs: [15. 12.  5. 12. 10.  7. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 247 acc: 0.91, outputs: [14. 13.  7. 11. 13.  6. 11. 11.  8.  6.]\n",
      "learningRate: 2 epochs: 248 acc: 0.93, outputs: [14. 13.  6. 11. 11.  7. 11. 11.  8.  8.]\n",
      "learningRate: 2 epochs: 249 acc: 0.92, outputs: [12. 12.  6. 12. 11.  5. 11. 13. 10.  8.]\n",
      "learningRate: 2 epochs: 250 acc: 0.93, outputs: [12. 13.  6. 11. 11.  7. 11. 10. 10.  9.]\n",
      "learningRate: 2 epochs: 251 acc: 0.94, outputs: [15. 12.  6. 11. 10.  7. 11. 11.  8.  9.]\n",
      "learningRate: 2 epochs: 252 acc: 0.93, outputs: [14. 12.  5. 12. 11.  7. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 253 acc: 0.93, outputs: [14. 12.  7. 12. 11.  5. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 254 acc: 0.93, outputs: [14. 13.  6. 11. 11.  7. 11. 11.  8.  8.]\n",
      "learningRate: 2 epochs: 255 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 256 acc: 0.94, outputs: [14. 14.  5. 11. 11.  6. 12. 11.  8.  8.]\n",
      "learningRate: 2 epochs: 257 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 258 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 259 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 260 acc: 0.94, outputs: [14. 13.  4. 13. 11.  6. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 261 acc: 0.95, outputs: [13. 13.  5. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 262 acc: 0.93, outputs: [14. 12.  6. 12. 11.  5. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 263 acc: 0.93, outputs: [12. 15.  5. 11. 11.  6. 11.  8. 10. 11.]\n",
      "learningRate: 2 epochs: 264 acc: 0.93, outputs: [14. 12.  7. 12. 11.  5. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 265 acc: 0.92, outputs: [12. 13.  4. 10. 11.  8. 11. 10. 11. 10.]\n",
      "learningRate: 2 epochs: 266 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 267 acc: 0.94, outputs: [12. 13.  5. 13. 11.  5. 11. 11. 10.  9.]\n",
      "learningRate: 2 epochs: 268 acc: 0.94, outputs: [14. 12.  6. 11. 11.  7. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 269 acc: 0.93, outputs: [13. 12.  6. 12. 11.  6. 11. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 270 acc: 0.93, outputs: [13. 12.  6. 11. 11.  7. 11. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 271 acc: 0.94, outputs: [13. 12.  6. 12. 11.  6. 11. 11.  9.  9.]\n",
      "learningRate: 2 epochs: 272 acc: 0.94, outputs: [14. 12.  6. 11. 11.  7. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 273 acc: 0.93, outputs: [12. 12.  6. 11. 11.  6. 11. 13. 10.  8.]\n",
      "learningRate: 2 epochs: 274 acc: 0.93, outputs: [12. 12.  7. 12. 11.  5. 11. 11. 10.  9.]\n",
      "learningRate: 2 epochs: 275 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learningRate: 2 epochs: 276 acc: 0.92, outputs: [14. 12.  6. 13. 12.  5. 11. 12.  8.  7.]\n",
      "learningRate: 2 epochs: 277 acc: 0.94, outputs: [12. 13.  5. 11. 11.  7. 11. 12. 10.  8.]\n",
      "learningRate: 2 epochs: 278 acc: 0.93, outputs: [13. 13.  5. 12. 11.  5. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 279 acc: 0.94, outputs: [14. 12.  6. 11. 12.  7. 11. 10.  8.  9.]\n",
      "learningRate: 2 epochs: 280 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 281 acc: 0.95, outputs: [14. 13.  5. 11. 11.  7. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 282 acc: 0.94, outputs: [12. 12.  6. 11. 11.  6. 12. 11. 10.  9.]\n",
      "learningRate: 2 epochs: 283 acc: 0.94, outputs: [14. 12.  6. 11. 11.  7. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 284 acc: 0.94, outputs: [14. 12.  6. 11. 11.  7. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 285 acc: 0.94, outputs: [14. 14.  6. 11. 11.  6. 11. 11.  8.  8.]\n",
      "learningRate: 2 epochs: 286 acc: 0.94, outputs: [14. 12.  7. 11. 11.  6. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 287 acc: 0.95, outputs: [14. 13.  5. 11. 11.  7. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 288 acc: 0.93, outputs: [14. 12.  6. 13. 11.  5. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 289 acc: 0.93, outputs: [13. 12.  6. 11. 11.  7. 11. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 290 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 291 acc: 0.93, outputs: [12. 12.  6. 11. 11.  6. 11. 13. 10.  8.]\n",
      "learningRate: 2 epochs: 292 acc: 0.93, outputs: [14. 12.  6. 13. 11.  6. 11. 12.  7.  8.]\n",
      "learningRate: 2 epochs: 293 acc: 0.93, outputs: [12. 12.  7. 12. 11.  5. 11. 11. 10.  9.]\n",
      "learningRate: 2 epochs: 294 acc: 0.93, outputs: [14. 12.  6. 12. 11.  5. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 295 acc: 0.93, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 296 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 297 acc: 0.91, outputs: [14. 12.  6. 11. 11.  6. 11. 16.  8.  5.]\n",
      "learningRate: 2 epochs: 298 acc: 0.94, outputs: [14. 12.  6. 11. 11.  7. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 299 acc: 0.92, outputs: [14. 12.  5. 14. 11.  5. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 300 acc: 0.93, outputs: [14. 12.  5. 12. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 301 acc: 0.9, outputs: [14. 12.  6. 11. 15.  7. 11. 11.  8.  5.]\n",
      "learningRate: 2 epochs: 302 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 303 acc: 0.93, outputs: [14. 12.  6. 11. 12.  6. 11. 13.  8.  7.]\n",
      "learningRate: 2 epochs: 304 acc: 0.93, outputs: [12. 13.  6. 11. 11.  7. 11. 10. 10.  9.]\n",
      "learningRate: 2 epochs: 305 acc: 0.91, outputs: [14. 12.  7. 11. 14.  6. 11. 11.  8.  6.]\n",
      "learningRate: 2 epochs: 306 acc: 0.93, outputs: [14. 13.  7. 11. 11.  6. 11. 11.  8.  8.]\n",
      "learningRate: 2 epochs: 307 acc: 0.94, outputs: [14. 12.  6. 11. 11.  7. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 308 acc: 0.93, outputs: [14. 13.  6. 11. 11.  6. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 309 acc: 0.94, outputs: [13. 13.  4. 12. 11.  8. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 310 acc: 0.94, outputs: [12. 12.  7. 12. 11.  4. 11. 11. 10. 10.]\n",
      "learningRate: 2 epochs: 311 acc: 0.9, outputs: [14. 12.  6. 13. 12.  5. 11. 14.  8.  5.]\n",
      "learningRate: 2 epochs: 312 acc: 0.94, outputs: [14. 12.  6. 11. 11.  7. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 313 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 314 acc: 0.91, outputs: [15. 12.  6. 13. 10.  5. 11. 13.  7.  8.]\n",
      "learningRate: 2 epochs: 315 acc: 0.93, outputs: [13. 13.  5. 11. 13.  7. 11. 11.  9.  7.]\n",
      "learningRate: 2 epochs: 316 acc: 0.94, outputs: [14. 12.  6. 11. 11.  7. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 317 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 318 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 319 acc: 0.93, outputs: [14. 12.  7. 11. 12.  6. 11. 12.  8.  7.]\n",
      "learningRate: 2 epochs: 320 acc: 0.94, outputs: [12. 12.  6. 11. 11.  7. 11. 11. 10.  9.]\n",
      "learningRate: 2 epochs: 321 acc: 0.94, outputs: [14. 12.  6. 12. 11.  6. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 322 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 323 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 324 acc: 0.95, outputs: [14. 12.  6. 11. 11.  7. 11. 11.  8.  9.]\n",
      "learningRate: 2 epochs: 325 acc: 0.93, outputs: [14. 13.  7. 11. 11.  6. 11. 11.  8.  8.]\n",
      "learningRate: 2 epochs: 326 acc: 0.94, outputs: [15. 12.  6. 11. 10.  6. 11. 12.  8.  9.]\n",
      "learningRate: 2 epochs: 327 acc: 0.92, outputs: [13. 12.  6. 12. 11.  5. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 328 acc: 0.94, outputs: [14. 12.  6. 11. 11.  7. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 329 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 330 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 331 acc: 0.95, outputs: [14. 12.  6. 11. 11.  6. 11. 12.  8.  9.]\n",
      "learningRate: 2 epochs: 332 acc: 0.88, outputs: [10. 12.  6. 15. 12.  5. 11. 12. 11.  6.]\n",
      "learningRate: 2 epochs: 333 acc: 0.95, outputs: [14. 13.  5. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 334 acc: 0.93, outputs: [13. 12.  5. 12. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 335 acc: 0.94, outputs: [14. 12.  6. 11. 11.  7. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 336 acc: 0.93, outputs: [15. 12.  6. 13. 10.  5. 11. 11.  8.  9.]\n",
      "learningRate: 2 epochs: 337 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 338 acc: 0.93, outputs: [14. 12.  6. 12. 11.  5. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 339 acc: 0.93, outputs: [14. 12.  5. 14. 11.  5. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 340 acc: 0.94, outputs: [13. 12.  6. 11. 11.  7. 11. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 341 acc: 0.91, outputs: [14. 12.  4. 16. 11.  5. 11. 12.  7.  8.]\n",
      "learningRate: 2 epochs: 342 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 343 acc: 0.95, outputs: [14. 12.  6. 11. 11.  6. 11. 12.  8.  9.]\n",
      "learningRate: 2 epochs: 344 acc: 0.93, outputs: [14. 12.  6. 13. 11.  5. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 345 acc: 0.91, outputs: [14. 12.  6. 12. 13.  5. 11. 13.  8.  6.]\n",
      "learningRate: 2 epochs: 346 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 347 acc: 0.92, outputs: [14. 12.  6. 11. 13.  6. 11. 13.  8.  6.]\n",
      "learningRate: 2 epochs: 348 acc: 0.93, outputs: [13. 12.  5. 12. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 349 acc: 0.91, outputs: [12. 12.  6. 11. 13.  6. 11. 13. 10.  6.]\n",
      "learningRate: 2 epochs: 350 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 351 acc: 0.93, outputs: [14. 12.  6. 12. 11.  5. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 352 acc: 0.94, outputs: [14. 12.  6. 12. 11.  5. 11. 12.  8.  9.]\n",
      "learningRate: 2 epochs: 353 acc: 0.95, outputs: [14. 12.  6. 11. 11.  7. 11. 11.  8.  9.]\n",
      "learningRate: 2 epochs: 354 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 355 acc: 0.93, outputs: [14. 12.  4. 14. 11.  6. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 356 acc: 0.94, outputs: [14. 12.  6. 12. 11.  6. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 357 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 358 acc: 0.92, outputs: [14. 12.  5. 13. 12.  6. 11. 12.  8.  7.]\n",
      "learningRate: 2 epochs: 359 acc: 0.95, outputs: [14. 12.  6. 11. 11.  7. 11. 11.  8.  9.]\n",
      "learningRate: 2 epochs: 360 acc: 0.95, outputs: [13. 12.  6. 11. 11.  6. 11. 12.  9.  9.]\n",
      "learningRate: 2 epochs: 361 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 362 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 363 acc: 0.94, outputs: [12. 12.  6. 11. 11.  7. 11. 11. 10.  9.]\n",
      "learningRate: 2 epochs: 364 acc: 0.92, outputs: [14. 12.  4. 16. 11.  4. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 365 acc: 0.95, outputs: [14. 13.  5. 11. 11.  7. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 366 acc: 0.94, outputs: [14. 12.  6. 11. 11.  7. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 367 acc: 0.92, outputs: [12. 11.  5. 11. 11.  5. 11. 13. 12.  9.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learningRate: 2 epochs: 368 acc: 0.88, outputs: [14. 12.  4. 18. 11.  5. 11. 12.  4.  9.]\n",
      "learningRate: 2 epochs: 369 acc: 0.95, outputs: [13. 12.  6. 11. 11.  7. 11. 11.  9.  9.]\n",
      "learningRate: 2 epochs: 370 acc: 0.95, outputs: [14. 14.  6. 11. 11.  6. 11. 10.  8.  9.]\n",
      "learningRate: 2 epochs: 371 acc: 0.94, outputs: [13. 12.  6. 13. 11.  5. 11. 11.  9.  9.]\n",
      "learningRate: 2 epochs: 372 acc: 0.93, outputs: [13. 12.  6. 12. 11.  5. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 373 acc: 0.93, outputs: [14. 12.  6. 11. 13.  7. 11. 10.  8.  8.]\n",
      "learningRate: 2 epochs: 374 acc: 0.94, outputs: [14. 12.  6. 13. 11.  5. 11. 11.  8.  9.]\n",
      "learningRate: 2 epochs: 375 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 376 acc: 0.95, outputs: [13. 12.  6. 12. 11.  6. 11. 11.  9.  9.]\n",
      "learningRate: 2 epochs: 377 acc: 0.94, outputs: [14. 12.  6. 11. 11.  7. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 378 acc: 0.94, outputs: [14. 12.  6. 11. 11.  7. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 379 acc: 0.94, outputs: [14. 12.  6. 11. 11.  7. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 380 acc: 0.93, outputs: [14. 12.  6. 13. 11.  5. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 381 acc: 0.92, outputs: [14. 12.  5. 15. 11.  4. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 382 acc: 0.95, outputs: [13. 12.  6. 11. 11.  7. 11. 11.  9.  9.]\n",
      "learningRate: 2 epochs: 383 acc: 0.93, outputs: [14. 12.  6. 13. 11.  5. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 384 acc: 0.95, outputs: [13. 12.  6. 11. 11.  6. 11. 11. 10.  9.]\n",
      "learningRate: 2 epochs: 385 acc: 0.93, outputs: [14. 12.  6. 11. 12.  7. 11. 12.  8.  7.]\n",
      "learningRate: 2 epochs: 386 acc: 0.93, outputs: [14. 12.  6. 13. 11.  5. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 387 acc: 0.93, outputs: [14. 13.  6. 13. 11.  5. 11. 10.  8.  9.]\n",
      "learningRate: 2 epochs: 388 acc: 0.96, outputs: [13. 15.  5. 11. 11.  6. 11. 10.  9.  9.]\n",
      "learningRate: 2 epochs: 389 acc: 0.93, outputs: [13. 12.  6. 13. 11.  5. 11. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 390 acc: 0.95, outputs: [14. 12.  6. 11. 11.  7. 11. 11.  8.  9.]\n",
      "learningRate: 2 epochs: 391 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 392 acc: 0.93, outputs: [14. 13.  5. 11. 13.  7. 11. 11.  8.  7.]\n",
      "learningRate: 2 epochs: 393 acc: 0.93, outputs: [12. 13.  4. 14. 11.  4. 11. 11. 11.  9.]\n",
      "learningRate: 2 epochs: 394 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 395 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 396 acc: 0.94, outputs: [12. 13.  5. 11. 11.  7. 11. 12. 10.  8.]\n",
      "learningRate: 2 epochs: 397 acc: 0.93, outputs: [14. 12.  6. 12. 11.  5. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 398 acc: 0.95, outputs: [14. 13.  5. 11. 11.  7. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 399 acc: 0.94, outputs: [13. 13.  4. 12. 11.  7. 11. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 400 acc: 0.95, outputs: [13. 12.  7. 11. 11.  6. 11. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 401 acc: 0.95, outputs: [13. 12.  7. 11. 11.  7. 11. 11.  9.  8.]\n",
      "learningRate: 2 epochs: 402 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 403 acc: 0.95, outputs: [14. 12.  7. 11. 11.  6. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 404 acc: 0.94, outputs: [13. 12.  6. 12. 11.  6. 11. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 405 acc: 0.89, outputs: [14. 12.  6. 13. 14.  5. 11. 12.  7.  6.]\n",
      "learningRate: 2 epochs: 406 acc: 0.93, outputs: [13. 12.  6. 12. 11.  5. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 407 acc: 0.92, outputs: [13. 12.  5. 13. 12.  6. 11. 11.  9.  8.]\n",
      "learningRate: 2 epochs: 408 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 409 acc: 0.94, outputs: [13. 12.  5. 12. 11.  6. 11. 12.  9.  9.]\n",
      "learningRate: 2 epochs: 410 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 411 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 412 acc: 0.95, outputs: [13. 12.  6. 11. 11.  6. 11. 12.  9.  9.]\n",
      "learningRate: 2 epochs: 413 acc: 0.95, outputs: [14. 12.  6. 11. 11.  6. 11. 12.  8.  9.]\n",
      "learningRate: 2 epochs: 414 acc: 0.95, outputs: [14. 12.  6. 11. 11.  7. 11. 11.  8.  9.]\n",
      "learningRate: 2 epochs: 415 acc: 0.93, outputs: [14. 12.  6. 12. 11.  5. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 416 acc: 0.96, outputs: [13. 12.  7. 11. 11.  7. 11. 10.  9.  9.]\n",
      "learningRate: 2 epochs: 417 acc: 0.94, outputs: [14. 12.  6. 11. 12.  6. 11. 11.  8.  9.]\n",
      "learningRate: 2 epochs: 418 acc: 0.95, outputs: [13. 12.  6. 11. 11.  6. 11. 12.  9.  9.]\n",
      "learningRate: 2 epochs: 419 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 420 acc: 0.94, outputs: [13. 12.  6. 11. 11.  7. 11. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 421 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 422 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 423 acc: 0.94, outputs: [12. 12.  7. 11. 11.  6. 11. 12. 10.  8.]\n",
      "learningRate: 2 epochs: 424 acc: 0.94, outputs: [13. 12.  6. 12. 11.  6. 11. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 425 acc: 0.93, outputs: [13. 12.  6. 12. 11.  5. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 426 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 427 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 428 acc: 0.93, outputs: [13. 12.  6. 12. 11.  5. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 429 acc: 0.94, outputs: [13. 12.  7. 13. 11.  5. 11. 11.  9.  8.]\n",
      "learningRate: 2 epochs: 430 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 431 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 432 acc: 0.9, outputs: [11. 13.  6. 15. 11.  5. 11. 10. 10.  8.]\n",
      "learningRate: 2 epochs: 433 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 434 acc: 0.95, outputs: [13. 12.  7. 11. 11.  6. 11. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 435 acc: 0.95, outputs: [13. 12.  7. 12. 11.  6. 11. 11.  9.  8.]\n",
      "learningRate: 2 epochs: 436 acc: 0.95, outputs: [13. 12.  7. 11. 11.  6. 11. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 437 acc: 0.95, outputs: [13. 13.  7. 12. 11.  6. 11.  9.  9.  9.]\n",
      "learningRate: 2 epochs: 438 acc: 0.95, outputs: [13. 12.  7. 12. 11.  6. 11. 11.  9.  8.]\n",
      "learningRate: 2 epochs: 439 acc: 0.93, outputs: [13. 12.  6. 11. 12.  6. 11. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 440 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 441 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 442 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 443 acc: 0.93, outputs: [13. 12.  5. 13. 11.  6. 11. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 444 acc: 0.93, outputs: [12. 12.  6. 11. 11.  6. 11. 13. 10.  8.]\n",
      "learningRate: 2 epochs: 445 acc: 0.94, outputs: [14. 12.  6. 11. 11.  7. 11. 12.  8.  8.]\n",
      "learningRate: 2 epochs: 446 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 447 acc: 0.95, outputs: [13. 12.  6. 12. 11.  6. 11. 11.  9.  9.]\n",
      "learningRate: 2 epochs: 448 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 449 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 450 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 451 acc: 0.95, outputs: [13. 12.  6. 11. 11.  6. 11. 12.  9.  9.]\n",
      "learningRate: 2 epochs: 452 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 453 acc: 0.94, outputs: [13. 12.  7. 13. 11.  5. 11. 11.  9.  8.]\n",
      "learningRate: 2 epochs: 454 acc: 0.95, outputs: [13. 12.  6. 11. 11.  6. 11. 12.  9.  9.]\n",
      "learningRate: 2 epochs: 455 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 456 acc: 0.94, outputs: [13. 12.  6. 12. 12.  6. 11. 10.  9.  9.]\n",
      "learningRate: 2 epochs: 457 acc: 0.95, outputs: [13. 12.  7. 11. 11.  6. 11. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 458 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 459 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learningRate: 2 epochs: 460 acc: 0.95, outputs: [14. 12.  6. 11. 11.  6. 11. 12.  8.  9.]\n",
      "learningRate: 2 epochs: 461 acc: 0.95, outputs: [13. 12.  6. 11. 11.  6. 11. 12.  9.  9.]\n",
      "learningRate: 2 epochs: 462 acc: 0.94, outputs: [14. 12.  7. 13. 12.  5. 11.  9.  8.  9.]\n",
      "learningRate: 2 epochs: 463 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 464 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 465 acc: 0.95, outputs: [14. 12.  6. 11. 11.  6. 11. 12.  8.  9.]\n",
      "learningRate: 2 epochs: 466 acc: 0.96, outputs: [13. 12.  7. 11. 11.  7. 11. 10.  9.  9.]\n",
      "learningRate: 2 epochs: 467 acc: 0.95, outputs: [13. 12.  6. 12. 11.  6. 11. 11.  9.  9.]\n",
      "learningRate: 2 epochs: 468 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 469 acc: 0.95, outputs: [13. 13.  5. 12. 11.  6. 11. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 470 acc: 0.94, outputs: [12. 12.  6. 11. 11.  6. 12. 11. 10.  9.]\n",
      "learningRate: 2 epochs: 471 acc: 0.94, outputs: [14. 12.  6. 11. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 472 acc: 0.94, outputs: [12. 12.  6. 11. 11.  5. 11. 12. 11.  9.]\n",
      "learningRate: 2 epochs: 473 acc: 0.95, outputs: [14. 12.  6. 11. 11.  6. 11. 12.  8.  9.]\n",
      "learningRate: 2 epochs: 474 acc: 0.93, outputs: [13. 13.  6. 11. 11.  6. 11. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 475 acc: 0.95, outputs: [13. 12.  6. 11. 11.  7. 11. 11.  9.  9.]\n",
      "learningRate: 2 epochs: 476 acc: 0.94, outputs: [13. 12.  6. 11. 12.  7. 11. 10.  9.  9.]\n",
      "learningRate: 2 epochs: 477 acc: 0.93, outputs: [14. 12.  6. 11.  9.  6. 11. 12.  9. 10.]\n",
      "learningRate: 2 epochs: 478 acc: 0.93, outputs: [14. 12.  7. 11. 13.  6. 11. 11.  8.  7.]\n",
      "learningRate: 2 epochs: 479 acc: 0.95, outputs: [13. 13.  5. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 480 acc: 0.95, outputs: [13. 13.  4. 12. 11.  7. 11. 11.  9.  9.]\n",
      "learningRate: 2 epochs: 481 acc: 0.94, outputs: [13. 12.  7. 10. 11.  6. 12. 12.  9.  8.]\n",
      "learningRate: 2 epochs: 482 acc: 0.95, outputs: [13. 13.  5. 12. 11.  5. 11. 12.  9.  9.]\n",
      "learningRate: 2 epochs: 483 acc: 0.93, outputs: [13. 12.  6. 11. 12.  7. 11. 11.  9.  8.]\n",
      "learningRate: 2 epochs: 484 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 485 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 486 acc: 0.93, outputs: [14. 12.  6. 12. 11.  6. 11. 13.  7.  8.]\n",
      "learningRate: 2 epochs: 487 acc: 0.93, outputs: [12. 12.  6. 11. 12.  6. 11. 11. 10.  9.]\n",
      "learningRate: 2 epochs: 488 acc: 0.94, outputs: [13. 12.  6. 11. 11.  6. 11. 13.  9.  8.]\n",
      "learningRate: 2 epochs: 489 acc: 0.94, outputs: [14. 13.  4. 12. 11.  6. 11. 13.  8.  8.]\n",
      "learningRate: 2 epochs: 490 acc: 0.94, outputs: [13. 12.  6. 12. 11.  6. 11. 10. 10.  9.]\n",
      "learningRate: 2 epochs: 491 acc: 0.93, outputs: [14. 13.  5. 12. 11.  6. 11. 13.  6.  9.]\n",
      "learningRate: 2 epochs: 492 acc: 0.93, outputs: [12. 12.  6. 13. 11.  5. 11. 11. 10.  9.]\n",
      "learningRate: 2 epochs: 493 acc: 0.96, outputs: [13. 13.  5. 11. 11.  6. 11. 12.  9.  9.]\n",
      "learningRate: 2 epochs: 494 acc: 0.95, outputs: [13. 13.  5. 11. 12.  6. 11. 11.  9.  9.]\n",
      "learningRate: 2 epochs: 495 acc: 0.95, outputs: [13. 12.  6. 11. 11.  6. 11. 12.  9.  9.]\n",
      "learningRate: 2 epochs: 496 acc: 0.94, outputs: [13. 12.  6. 11. 12.  6. 11. 11.  9.  9.]\n",
      "learningRate: 2 epochs: 497 acc: 0.95, outputs: [14. 12.  6. 11. 11.  6. 11. 12.  8.  9.]\n",
      "learningRate: 2 epochs: 498 acc: 0.93, outputs: [14. 12.  6. 11. 13.  6. 11. 11.  8.  8.]\n",
      "learningRate: 2 epochs: 499 acc: 0.93, outputs: [13. 12.  6. 12. 11.  5. 11. 13.  9.  8.]\n",
      "best acc: 0.96 on epoch: 388\n"
     ]
    }
   ],
   "source": [
    "net = gridSearch(train_X, train_y, test_X, test_y, batchSize=100, learningRates=[2], epochs=500, lamb=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2f632dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9122,\n",
       " array([ 994., 1246.,  947.,  969.,  989.,  790., 1035.,  947.,  985.,\n",
       "        1098.]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testNetwork(net, test_X, test_y, len(test_X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
