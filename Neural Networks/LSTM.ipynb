{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d19ba97a",
   "metadata": {},
   "source": [
    "Base for this notebook: https://colah.github.io/posts/2015-08-Understanding-LSTMs/ <br>\n",
    "Got the derivatives from: https://medium.com/@aidangomez/let-s-do-this-f9b699de31d9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14a426d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rd\n",
    "from keras.datasets import imdb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "378ffc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(n: float):\n",
    "    return 1.0/(1.0+np.exp(-n))\n",
    "\n",
    "def sigmoid_derivative(n: float):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(n)*(1-sigmoid(n))\n",
    "    \n",
    "def tanh(n: float):\n",
    "    return np.tanh(n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9359675d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros([500,1,1])\n",
    "w = np.zeros([1,500])\n",
    "b = np.zeros([500])\n",
    "sigmoid(np.dot(x[0],w) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25b767c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(X):\n",
    "    maxLen = len(max(X, key=len))\n",
    "    for i in range(len(X)):\n",
    "        X[i] = np.pad(X[i], (0 ,maxLen - len(X[i])), 'constant', constant_values=(0, 0))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "125ed652",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = 500\n",
    "(train_X, train_y), (test_X, test_y) = imdb.load_data(seed=42, num_words=500, maxlen=maxLen)\n",
    "train_X = padding(train_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b14842db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1  13 244   6 194 337   6   2   2   2   5 207 110  98  32   5  14   9\n",
      "  31   7   4 118  45 163   2   5   6 356  13 386  14  18  32   2  45  87\n",
      "  18 117 362  88  45  73   2   5  87  18   2   5   2  88  45 163   5  24\n",
      " 120   4 350  13 296  12  54  13  16 117   5  13 131 106  12 150  12  47\n",
      "  87 411  15  61 223   5  13   2  32   4  58   4 116   9  87   5  12 115\n",
      " 214 154  48  25  40   2   2   5   2  25  80 119  14 207 296 111   6   2\n",
      "  20  11  61  58   5  14   9   4 118   7  98  32   2   2  13   2 386  14\n",
      "  20   5  32   4   2   2   2 287  36  32   2   8  32   2   5  26  32   2\n",
      "   5  55 441   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(train_X[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b0b19583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = np.zeros((500, 1, 500))\n",
    "h[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2da7a1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    \n",
    "    \"\"\"\n",
    "    h = array of outputs\n",
    "    x = array of inputs\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, nInputs, nFeatures, nCells, nOutputs, batchSize):\n",
    "        nGates = 4\n",
    "        if nCells < nOutputs:\n",
    "            print('the number of cells cannot be less than the number of outputs')\n",
    "        \n",
    "        # [t][i][j], t = timestep, i = which batch, j = which cell or feature\n",
    "        x = np.zeros((nInputs, batchSize, nFeatures))\n",
    "        h = np.zeros((nInputs, batchSize, nCells))\n",
    "        i = np.zeros((nInputs, batchSize, nCells))\n",
    "        f = np.zeros((nInputs, batchSize, nCells))\n",
    "        o = np.zeros((nInputs, batchSize, nCells))\n",
    "        tildeC = np.zeros((nInputs, batchSize, nCells))\n",
    "        C = np.zeros((nInputs, batchSize, nCells))\n",
    "        wxScale = 1/np.sqrt(nFeatures*nCells)\n",
    "        whScale = 1/np.sqrt(nCells*nCells)\n",
    "        Wxi = np.random.normal(loc=0,scale=wxScale,size=[nFeatures, nCells])\n",
    "        Wxf = np.random.normal(loc=0,scale=wxScale,size=[nFeatures, nCells])\n",
    "        Wxc = np.random.normal(loc=0,scale=wxScale,size=[nFeatures, nCells])\n",
    "        Wxo = np.random.normal(loc=0,scale=wxScale,size=[nFeatures, nCells])\n",
    "        Whi = np.random.normal(loc=0,scale=wxScale,size=[nCells, nCells])\n",
    "        Whf = np.random.normal(loc=0,scale=wxScale,size=[nCells, nCells])\n",
    "        Whc = np.random.normal(loc=0,scale=wxScale,size=[nCells, nCells])\n",
    "        Who = np.random.normal(loc=0,scale=wxScale,size=[nCells, nCells])\n",
    "        bi = np.random.normal(loc=0,scale=1,size=[nCells])\n",
    "        bf = np.random.normal(loc=0,scale=1,size=[nCells])\n",
    "        bc = np.random.normal(loc=0,scale=1,size=[nCells])\n",
    "        bo = np.random.normal(loc=0,scale=1,size=[nCells])\n",
    "        self.x = x\n",
    "        self.h = h\n",
    "        self.i = i\n",
    "        self.f = f\n",
    "        self.o = o\n",
    "        self.tildeC = tildeC\n",
    "        self.C = C\n",
    "        self.Wxi = Wxi\n",
    "        self.Wxf = Wxf\n",
    "        self.Wxc = Wxc\n",
    "        self.Wxo = Wxo\n",
    "        self.Whi = Whi\n",
    "        self.Whf = Whf\n",
    "        self.Whc = Whc\n",
    "        self.Who = Who\n",
    "        self.bi = bi\n",
    "        self.bf = bf\n",
    "        self.bc = bc\n",
    "        self.bo = bo\n",
    "        self.nCells = nCells\n",
    "        self.nGates = nGates\n",
    "        \n",
    "        \n",
    "    #the np.array(a) and np.array(b) can be removed after batchSize is implemented\n",
    "        \n",
    "    def forgetGate(self, t):\n",
    "        if t == 0:\n",
    "            self.f[t] = sigmoid(np.dot(self.x[t], self.Wxf) + self.bf)\n",
    "        else:\n",
    "            self.f[t] = sigmoid(np.dot(self.h[t-1], self.Whf) + np.dot(self.x[t], self.Wxf) + self.bf)\n",
    "        return self.f[t]\n",
    "    \n",
    "    def inputGate(self, t):\n",
    "        if t == 0:\n",
    "            self.i[t] = sigmoid(np.dot(self.x[t], self.Wxi) + self.bi)\n",
    "            self.tildeC[t] = tanh(np.dot(self.x[t], self.Wxc) + self.bc) \n",
    "        else:\n",
    "            self.i[t] = sigmoid(np.dot(self.h[t-1], self.Whi) + np.dot(self.x[t], self.Wxi) + self.bi)\n",
    "            self.tildeC[t] = tanh(np.dot(self.h[t-1], self.Whc) + np.dot(self.x[t], self.Wxc) + self.bc)        \n",
    "        return self.i[t]*self.tildeC[t]\n",
    "    \n",
    "    def outputGate(self, t, newC):\n",
    "        if t == 0:\n",
    "            self.o[t] = sigmoid(np.dot(self.x[t], self.Wxo) + self.bo)\n",
    "        else:\n",
    "            self.o[t] = sigmoid(np.dot(self.h[t-1], self.Who) + np.dot(self.x[t], self.Wxo) + self.bo)\n",
    "        self.h[t] = self.o[t]*tanh(newC)\n",
    "        return self.h[t]\n",
    "      \n",
    "    def getNewState(self, t, xElement):\n",
    "        newC = self.C[t-1]*self.forgetGate(t)\n",
    "        newC = newC + self.inputGate(t)\n",
    "        newH = self.outputGate(t, newC)\n",
    "        return newC, newH\n",
    "                             \n",
    "    def setInput(self, x):\n",
    "        C = 0\n",
    "        self.x[0] = x[0]\n",
    "        self.C[0], self.h[0] = self.getNewState(0, x[0])\n",
    "        for t in range(1, self.nCells):\n",
    "            self.x[t] = x[t]\n",
    "            self.C[t], self.h[t] = self.getNewState(t, x[t])\n",
    "        return \n",
    "    \n",
    "   \n",
    "    def backProp(self):\n",
    "        deltaOut = 0\n",
    "        # a = C~, state = C\n",
    "        i = self.i\n",
    "        f = self.f\n",
    "        C = self.C\n",
    "        o = self.o\n",
    "        deltaGates = np.zeros([self.nCells, self.nGates])\n",
    "        for t in range(nCells, 0, -1):\n",
    "            delta = h[t] - y[t]\n",
    "            deltaOut = delta + deltaOut\n",
    "            deltaState = deltaOut*o[t]*(1 - tanh(C[t])**2) + deltaState[t+1]*f[t+1]\n",
    "            deltaC = deltaState[t]*i[t]*(1 - C[t]**2)\n",
    "            deltaI = deltaState[t]*C[t]*i[t]*(1 - i[t])\n",
    "            deltaF = deltaState[t]*C[t-1]*f[t]*(1 - f[t])\n",
    "            deltaO = deltaOut[t]*tanh(C[t])*o[t]*(1 - o[t])\n",
    "            deltaGates[t] = np.array([deltaA[t], deltaI[t], deltaF[t], deltaO[t]])\n",
    "        \n",
    "        deltaW = 0\n",
    "        deltaU = 0\n",
    "        deltaB = 0\n",
    "        for t in range(nInputs):\n",
    "            deltaW += np.outer(deltaGates[t], self.x[t])\n",
    "            deltaB += deltaGates[t]\n",
    "            deltaU += np.outer(deltaGates[t+1], self.h[t])\n",
    "        return deltaW, deltaU, deltaB            \n",
    "              \n",
    "                 \n",
    "    def SGD(self, X: list, y: list, batchSize: int, nEpochs: int, learningRate, lamb):\n",
    "        \"\"\"\n",
    "        Implementation of Stochastic Gradient Descent\n",
    "\n",
    "        It takes as input the network, the MNIST dataset, the MNIST labels of the dataset, \n",
    "        the size of the batch to do gradient descent, the number of epochs it should run,\n",
    "        the learning rate eta (I found the best eta to be in the order of 1s)\n",
    "        and the regularization term lambda\n",
    "\n",
    "        It returns a trained network\n",
    "        \"\"\"\n",
    "        bestAcc = 0\n",
    "        bestEpoch = 0\n",
    "        eta = learningRate\n",
    "        etaChangeEpoch = 0\n",
    "        for epoch in range(nEpochs):\n",
    "            batch = rd.sample(range(len(X)), batchSize)\n",
    "            nablaW = np.zeros(self.nGates)\n",
    "            nablaU = np.zeros(self.nGates)\n",
    "            nablaB = np.zeros(self.nGates)\n",
    "            for i in batch:\n",
    "                self.setInput(X[i])\n",
    "                # finding what should be modified based on this particular example\n",
    "                deltaNablaW, deltaNablaU, deltaNablaB = LSTM.backProp(net, y[i])\n",
    "                # passing this modifications to our overall modifications matrices\n",
    "                nablaW += deltaNablaW\n",
    "                nablaU += deltaNablaU\n",
    "                nablaB += deltaNablaB\n",
    "\n",
    "            # applying the changes to our network\n",
    "            self.b = self.b - eta * (nablaB/batchSize) \n",
    "            self.w = self.w - eta * (nablaW/batchSize) - eta * (lamb/batchSize) *  self.w\n",
    "            self.u = self.u - eta * (nablaU/batchSize) - eta * (lamb/batchSize) *  self.u\n",
    "            acc, outputs = testNetwork(X, y, nTests=batchSize)\n",
    "            if acc > bestAcc:\n",
    "                bestAcc = acc\n",
    "                bestEpoch = epoch\n",
    "            print(f'learningRate: {learningRate} epochs: {epoch} acc: {acc}, outputs: {outputs}')\n",
    "        print(f'best acc: {bestAcc} on epoch: {bestEpoch}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "10120406",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 499 is out of bounds for axis 0 with size 499",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-f86040254c74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mlstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnEpochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearningRate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlamb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-136-db55205135f3>\u001b[0m in \u001b[0;36mSGD\u001b[1;34m(self, X, y, batchSize, nEpochs, learningRate, lamb)\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[0mnablaB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnGates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m                 \u001b[1;31m# finding what should be modified based on this particular example\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                 \u001b[0mdeltaNablaW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeltaNablaU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeltaNablaB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackProp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-136-db55205135f3>\u001b[0m in \u001b[0;36msetInput\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetNewState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnCells\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetNewState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 499 is out of bounds for axis 0 with size 499"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(nInputs=500, nFeatures=1, nCells=500, nOutputs=1, batchSize=1)\n",
    "\n",
    "\n",
    "lstm.SGD(train_X, train_y, batchSize=100, nEpochs=100, learningRate = 1, lamb = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "d026ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testNetwork(net: Network, test_X, test_y, nTests: int):\n",
    "    \"\"\"\n",
    "    A function to test our network\n",
    "    \n",
    "    It returns the overall accuracy and the numbers our network guessed\n",
    "    \"\"\"\n",
    "    \n",
    "    correctOutput = 0\n",
    "    X = test_X[:nTests]\n",
    "    y = test_y[:nTests]\n",
    "    outputs = np.zeros(10)\n",
    "    for i in range(nTests):\n",
    "        net = setInput(net, X[i])\n",
    "        networkOutput = np.argmax(net.a[-1])\n",
    "        outputs[networkOutput] += 1\n",
    "        #print(f\"number: {y[i]}, networkOutput: {networkOutput}, activations: {net.a[-1]}\")\n",
    "        if y[i] == networkOutput:\n",
    "            correctOutput += 1\n",
    "    acc = correctOutput/nTests\n",
    "    return acc, outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "38ebf075",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initializing the network and the dataset\n",
    "\n",
    "net = Network([784,30,10])\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "5918a0e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learningRate: 2 epochs: 0 acc: 0.1, outputs: [ 0.  0. 10.  0.  0.  0.  0.  0.  0.  0.]\n",
      "learningRate: 2 epochs: 1 acc: 0.0, outputs: [0. 0. 0. 0. 0. 6. 0. 4. 0. 0.]\n",
      "learningRate: 2 epochs: 2 acc: 0.1, outputs: [ 0.  0. 10.  0.  0.  0.  0.  0.  0.  0.]\n",
      "learningRate: 2 epochs: 3 acc: 0.0, outputs: [ 0.  0.  0.  0.  0.  0. 10.  0.  0.  0.]\n",
      "learningRate: 2 epochs: 4 acc: 0.0, outputs: [ 0.  0.  0.  0.  0.  0.  0. 10.  0.  0.]\n",
      "learningRate: 2 epochs: 5 acc: 0.1, outputs: [0. 0. 0. 0. 6. 0. 0. 0. 4. 0.]\n",
      "learningRate: 2 epochs: 6 acc: 0.1, outputs: [0. 0. 0. 0. 2. 0. 0. 0. 8. 0.]\n",
      "learningRate: 2 epochs: 7 acc: 0.1, outputs: [10.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "learningRate: 2 epochs: 8 acc: 0.3, outputs: [0. 1. 0. 0. 9. 0. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 9 acc: 0.1, outputs: [8. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 10 acc: 0.2, outputs: [ 0.  0.  0.  0. 10.  0.  0.  0.  0.  0.]\n",
      "learningRate: 2 epochs: 11 acc: 0.2, outputs: [0. 2. 0. 0. 0. 0. 0. 3. 5. 0.]\n",
      "learningRate: 2 epochs: 12 acc: 0.2, outputs: [0. 2. 0. 0. 0. 0. 0. 8. 0. 0.]\n",
      "learningRate: 2 epochs: 13 acc: 0.3, outputs: [0. 3. 0. 0. 0. 0. 0. 7. 0. 0.]\n",
      "learningRate: 2 epochs: 14 acc: 0.5, outputs: [0. 6. 0. 0. 4. 0. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 15 acc: 0.1, outputs: [10.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "learningRate: 2 epochs: 16 acc: 0.3, outputs: [ 0. 10.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "learningRate: 2 epochs: 17 acc: 0.3, outputs: [0. 0. 0. 5. 5. 0. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 18 acc: 0.3, outputs: [0. 2. 0. 2. 0. 0. 0. 6. 0. 0.]\n",
      "learningRate: 2 epochs: 19 acc: 0.5, outputs: [0. 8. 0. 0. 2. 0. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 20 acc: 0.3, outputs: [1. 3. 0. 0. 0. 0. 0. 6. 0. 0.]\n",
      "learningRate: 2 epochs: 21 acc: 0.4, outputs: [1. 7. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "learningRate: 2 epochs: 22 acc: 0.1, outputs: [0. 1. 0. 0. 0. 0. 9. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 23 acc: 0.6, outputs: [2. 3. 0. 0. 5. 0. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 24 acc: 0.4, outputs: [1. 3. 0. 0. 0. 0. 0. 3. 3. 0.]\n",
      "learningRate: 2 epochs: 25 acc: 0.4, outputs: [2. 3. 0. 0. 0. 0. 0. 2. 1. 2.]\n",
      "learningRate: 2 epochs: 26 acc: 0.7, outputs: [1. 3. 0. 3. 3. 0. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 27 acc: 0.7, outputs: [1. 3. 0. 2. 4. 0. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 28 acc: 0.5, outputs: [5. 3. 0. 0. 2. 0. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 29 acc: 0.7, outputs: [1. 3. 3. 0. 3. 0. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 30 acc: 0.6, outputs: [4. 3. 0. 0. 3. 0. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 31 acc: 0.6, outputs: [1. 3. 0. 3. 1. 0. 0. 2. 0. 0.]\n",
      "learningRate: 2 epochs: 32 acc: 0.6, outputs: [3. 3. 0. 1. 2. 0. 1. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 33 acc: 0.7, outputs: [1. 3. 0. 2. 4. 0. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 34 acc: 0.6, outputs: [1. 2. 0. 4. 3. 0. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 35 acc: 0.6, outputs: [1. 3. 0. 3. 1. 0. 0. 2. 0. 0.]\n",
      "learningRate: 2 epochs: 36 acc: 0.8, outputs: [1. 3. 0. 1. 3. 2. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 37 acc: 0.7, outputs: [1. 3. 0. 2. 4. 0. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 38 acc: 0.7, outputs: [1. 3. 0. 2. 3. 0. 0. 0. 1. 0.]\n",
      "learningRate: 2 epochs: 39 acc: 0.7, outputs: [1. 3. 0. 2. 2. 0. 0. 0. 2. 0.]\n",
      "learningRate: 2 epochs: 40 acc: 0.6, outputs: [1. 3. 0. 1. 5. 0. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 41 acc: 0.6, outputs: [1. 3. 0. 3. 0. 0. 0. 0. 0. 3.]\n",
      "learningRate: 2 epochs: 42 acc: 0.6, outputs: [1. 3. 0. 2. 0. 0. 0. 0. 1. 3.]\n",
      "learningRate: 2 epochs: 43 acc: 0.8, outputs: [1. 3. 1. 2. 1. 0. 0. 0. 0. 2.]\n",
      "learningRate: 2 epochs: 44 acc: 0.6, outputs: [1. 3. 0. 1. 1. 0. 3. 1. 0. 0.]\n",
      "learningRate: 2 epochs: 45 acc: 0.8, outputs: [1. 3. 1. 2. 2. 0. 0. 1. 0. 0.]\n",
      "learningRate: 2 epochs: 46 acc: 0.4, outputs: [1. 2. 0. 5. 0. 0. 0. 0. 0. 2.]\n",
      "learningRate: 2 epochs: 47 acc: 0.7, outputs: [1. 3. 1. 0. 3. 0. 0. 0. 2. 0.]\n",
      "learningRate: 2 epochs: 48 acc: 0.4, outputs: [1. 1. 0. 0. 2. 0. 0. 0. 6. 0.]\n",
      "learningRate: 2 epochs: 49 acc: 0.6, outputs: [2. 3. 0. 1. 2. 0. 0. 1. 1. 0.]\n",
      "learningRate: 2 epochs: 50 acc: 0.8, outputs: [1. 3. 1. 2. 3. 0. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 51 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 52 acc: 0.9, outputs: [1. 3. 1. 1. 3. 1. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 53 acc: 0.6, outputs: [4. 3. 0. 0. 3. 0. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 54 acc: 0.6, outputs: [0. 3. 0. 0. 2. 3. 0. 2. 0. 0.]\n",
      "learningRate: 2 epochs: 55 acc: 0.5, outputs: [0. 2. 0. 0. 2. 6. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 56 acc: 0.6, outputs: [1. 3. 0. 0. 3. 0. 0. 0. 3. 0.]\n",
      "learningRate: 2 epochs: 57 acc: 0.7, outputs: [1. 2. 1. 0. 2. 0. 0. 0. 3. 1.]\n",
      "learningRate: 2 epochs: 58 acc: 0.8, outputs: [1. 3. 3. 0. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 59 acc: 0.6, outputs: [1. 3. 0. 0. 2. 0. 0. 1. 3. 0.]\n",
      "learningRate: 2 epochs: 60 acc: 0.7, outputs: [2. 2. 2. 0. 2. 0. 0. 0. 1. 1.]\n",
      "learningRate: 2 epochs: 61 acc: 1.0, outputs: [1. 3. 1. 1. 2. 1. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 62 acc: 0.7, outputs: [1. 3. 0. 0. 4. 2. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 63 acc: 0.7, outputs: [0. 4. 0. 0. 2. 3. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 64 acc: 0.6, outputs: [1. 3. 0. 0. 0. 2. 0. 1. 0. 3.]\n",
      "learningRate: 2 epochs: 65 acc: 0.8, outputs: [0. 3. 1. 0. 2. 2. 0. 0. 1. 1.]\n",
      "learningRate: 2 epochs: 66 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 67 acc: 0.7, outputs: [1. 3. 2. 0. 3. 0. 1. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 68 acc: 0.8, outputs: [1. 3. 0. 0. 2. 1. 0. 0. 2. 1.]\n",
      "learningRate: 2 epochs: 69 acc: 0.9, outputs: [1. 3. 1. 1. 2. 1. 0. 1. 0. 0.]\n",
      "learningRate: 2 epochs: 70 acc: 0.8, outputs: [1. 3. 1. 1. 2. 0. 0. 0. 1. 1.]\n",
      "learningRate: 2 epochs: 71 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 72 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 73 acc: 0.8, outputs: [1. 3. 1. 0. 2. 1. 1. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 74 acc: 0.9, outputs: [1. 3. 1. 0. 2. 2. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 75 acc: 0.8, outputs: [3. 3. 0. 1. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 76 acc: 0.9, outputs: [1. 3. 0. 1. 2. 1. 1. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 77 acc: 1.0, outputs: [1. 3. 1. 1. 2. 1. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 78 acc: 1.0, outputs: [1. 3. 1. 1. 2. 1. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 79 acc: 0.7, outputs: [1. 3. 0. 2. 1. 0. 0. 0. 0. 3.]\n",
      "learningRate: 2 epochs: 80 acc: 0.7, outputs: [1. 3. 0. 3. 2. 0. 0. 1. 0. 0.]\n",
      "learningRate: 2 epochs: 81 acc: 0.8, outputs: [1. 3. 0. 2. 3. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 82 acc: 0.8, outputs: [1. 3. 0. 2. 2. 0. 0. 1. 0. 1.]\n",
      "learningRate: 2 epochs: 83 acc: 0.7, outputs: [2. 3. 0. 2. 2. 0. 0. 1. 0. 0.]\n",
      "learningRate: 2 epochs: 84 acc: 0.7, outputs: [2. 3. 0. 0. 2. 1. 0. 2. 0. 0.]\n",
      "learningRate: 2 epochs: 85 acc: 0.8, outputs: [1. 3. 1. 1. 2. 0. 0. 0. 1. 1.]\n",
      "learningRate: 2 epochs: 86 acc: 0.9, outputs: [2. 3. 0. 1. 2. 1. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 87 acc: 0.9, outputs: [1. 3. 0. 1. 2. 1. 0. 0. 0. 2.]\n",
      "learningRate: 2 epochs: 88 acc: 0.9, outputs: [1. 3. 0. 1. 3. 1. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 89 acc: 0.9, outputs: [2. 3. 0. 1. 2. 1. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 90 acc: 0.8, outputs: [2. 3. 0. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 91 acc: 0.8, outputs: [1. 3. 1. 2. 3. 0. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 92 acc: 0.9, outputs: [1. 3. 0. 1. 2. 1. 0. 0. 1. 1.]\n",
      "learningRate: 2 epochs: 93 acc: 0.8, outputs: [1. 3. 1. 2. 3. 0. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 94 acc: 0.8, outputs: [1. 3. 1. 2. 3. 0. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 95 acc: 1.0, outputs: [1. 3. 1. 1. 2. 1. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 96 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 97 acc: 0.9, outputs: [1. 3. 1. 0. 2. 2. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 98 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 99 acc: 0.8, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 1. 0.]\n",
      "learningRate: 2 epochs: 100 acc: 0.8, outputs: [1. 3. 0. 1. 4. 1. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 101 acc: 0.9, outputs: [1. 3. 0. 1. 3. 1. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 102 acc: 0.8, outputs: [1. 3. 0. 1. 4. 1. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 103 acc: 0.8, outputs: [2. 3. 1. 1. 2. 0. 1. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 104 acc: 0.8, outputs: [1. 3. 0. 2. 2. 0. 0. 0. 0. 2.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learningRate: 2 epochs: 105 acc: 1.0, outputs: [1. 3. 1. 1. 2. 1. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 106 acc: 1.0, outputs: [1. 3. 1. 1. 2. 1. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 107 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 108 acc: 0.8, outputs: [1. 3. 0. 2. 2. 0. 0. 0. 1. 1.]\n",
      "learningRate: 2 epochs: 109 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 110 acc: 0.8, outputs: [1. 3. 1. 2. 3. 0. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 111 acc: 0.6, outputs: [1. 1. 3. 2. 2. 0. 0. 1. 0. 0.]\n",
      "learningRate: 2 epochs: 112 acc: 0.8, outputs: [1. 3. 0. 2. 2. 0. 0. 0. 1. 1.]\n",
      "learningRate: 2 epochs: 113 acc: 0.8, outputs: [1. 3. 0. 2. 2. 0. 0. 0. 1. 1.]\n",
      "learningRate: 2 epochs: 114 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 115 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 116 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 117 acc: 0.8, outputs: [1. 3. 0. 2. 2. 0. 0. 0. 0. 2.]\n",
      "learningRate: 2 epochs: 118 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 119 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 120 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 121 acc: 0.8, outputs: [1. 3. 0. 0. 3. 1. 0. 0. 1. 1.]\n",
      "learningRate: 2 epochs: 122 acc: 0.7, outputs: [1. 3. 1. 0. 0. 1. 0. 0. 1. 3.]\n",
      "learningRate: 2 epochs: 123 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 124 acc: 0.7, outputs: [1. 3. 0. 0. 2. 1. 0. 1. 2. 0.]\n",
      "learningRate: 2 epochs: 125 acc: 0.9, outputs: [1. 3. 1. 1. 2. 1. 0. 1. 0. 0.]\n",
      "learningRate: 2 epochs: 126 acc: 0.8, outputs: [1. 3. 1. 2. 3. 0. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 127 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 128 acc: 0.6, outputs: [1. 2. 0. 2. 2. 0. 0. 2. 1. 0.]\n",
      "learningRate: 2 epochs: 129 acc: 0.7, outputs: [1. 3. 0. 2. 2. 0. 0. 2. 0. 0.]\n",
      "learningRate: 2 epochs: 130 acc: 0.7, outputs: [1. 3. 0. 2. 4. 0. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 131 acc: 0.8, outputs: [1. 3. 0. 2. 2. 0. 0. 0. 0. 2.]\n",
      "learningRate: 2 epochs: 132 acc: 0.8, outputs: [1. 3. 0. 2. 2. 0. 0. 0. 0. 2.]\n",
      "learningRate: 2 epochs: 133 acc: 0.7, outputs: [1. 3. 0. 0. 2. 0. 0. 0. 2. 2.]\n",
      "learningRate: 2 epochs: 134 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 135 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 136 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 137 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 138 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 139 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 140 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 141 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 142 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 143 acc: 0.9, outputs: [2. 3. 1. 1. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 144 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 145 acc: 0.9, outputs: [1. 3. 0. 1. 2. 1. 0. 0. 0. 2.]\n",
      "learningRate: 2 epochs: 146 acc: 0.8, outputs: [1. 3. 0. 2. 3. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 147 acc: 0.8, outputs: [1. 3. 0. 2. 2. 0. 0. 0. 0. 2.]\n",
      "learningRate: 2 epochs: 148 acc: 1.0, outputs: [1. 3. 1. 1. 2. 1. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 149 acc: 0.9, outputs: [1. 3. 0. 1. 2. 1. 0. 0. 0. 2.]\n",
      "learningRate: 2 epochs: 150 acc: 0.9, outputs: [1. 3. 0. 1. 2. 1. 0. 0. 0. 2.]\n",
      "learningRate: 2 epochs: 151 acc: 0.9, outputs: [1. 3. 0. 1. 2. 1. 0. 0. 0. 2.]\n",
      "learningRate: 2 epochs: 152 acc: 0.9, outputs: [1. 3. 0. 1. 2. 1. 0. 0. 0. 2.]\n",
      "learningRate: 2 epochs: 153 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 154 acc: 1.0, outputs: [1. 3. 1. 1. 2. 1. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 155 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 156 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 157 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 158 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 159 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 160 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 161 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 162 acc: 1.0, outputs: [1. 3. 1. 1. 2. 1. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 163 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 164 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 165 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 166 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 167 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 168 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 169 acc: 0.8, outputs: [1. 3. 0. 2. 2. 0. 0. 0. 1. 1.]\n",
      "learningRate: 2 epochs: 170 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 171 acc: 0.9, outputs: [1. 3. 0. 1. 2. 1. 0. 0. 0. 2.]\n",
      "learningRate: 2 epochs: 172 acc: 0.9, outputs: [1. 3. 0. 1. 2. 1. 0. 0. 0. 2.]\n",
      "learningRate: 2 epochs: 173 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 174 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 175 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 176 acc: 1.0, outputs: [1. 3. 1. 1. 2. 1. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 177 acc: 0.8, outputs: [1. 3. 0. 2. 2. 0. 0. 0. 1. 1.]\n",
      "learningRate: 2 epochs: 178 acc: 0.8, outputs: [1. 3. 0. 2. 2. 0. 0. 0. 1. 1.]\n",
      "learningRate: 2 epochs: 179 acc: 0.8, outputs: [1. 3. 0. 2. 2. 0. 0. 1. 0. 1.]\n",
      "learningRate: 2 epochs: 180 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 181 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 182 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 183 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 184 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 185 acc: 0.9, outputs: [2. 3. 1. 1. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 186 acc: 0.8, outputs: [2. 3. 0. 1. 2. 0. 0. 0. 0. 2.]\n",
      "learningRate: 2 epochs: 187 acc: 0.9, outputs: [2. 3. 1. 1. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 188 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 189 acc: 0.9, outputs: [2. 3. 1. 1. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 190 acc: 0.6, outputs: [1. 3. 0. 2. 0. 0. 0. 0. 1. 3.]\n",
      "learningRate: 2 epochs: 191 acc: 0.9, outputs: [1. 3. 0. 1. 2. 1. 0. 0. 0. 2.]\n",
      "learningRate: 2 epochs: 192 acc: 0.7, outputs: [2. 3. 0. 1. 4. 0. 0. 0. 0. 0.]\n",
      "learningRate: 2 epochs: 193 acc: 0.8, outputs: [2. 3. 0. 1. 3. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 194 acc: 0.9, outputs: [1. 3. 0. 1. 3. 1. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 195 acc: 0.8, outputs: [3. 3. 0. 1. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 196 acc: 0.8, outputs: [3. 3. 0. 1. 2. 0. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 197 acc: 0.8, outputs: [1. 3. 0. 2. 2. 0. 0. 0. 1. 1.]\n",
      "learningRate: 2 epochs: 198 acc: 1.0, outputs: [1. 3. 1. 1. 2. 1. 0. 0. 0. 1.]\n",
      "learningRate: 2 epochs: 199 acc: 0.9, outputs: [1. 3. 1. 2. 2. 0. 0. 0. 0. 1.]\n",
      "best acc: 1.0 on epoch: 61\n"
     ]
    }
   ],
   "source": [
    "net = gridSearch(net, train_X, train_y, test_X, test_y, batchSize=100, learningRates=[1.6], epochs=200, lamb=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "d2f632dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7948,\n",
       " array([ 892., 1165.,  616., 1402.,  804.,  513., 1151., 1287.,  949.,\n",
       "        1221.]))"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testNetwork(net, test_X, test_y, len(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "4e5602a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing our network in action\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pick a sample to plot\n",
    "sample = 50099\n",
    "image = train_X[sample]\n",
    "# plot the sample\n",
    "fig = plt.figure\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "net = setInput(net, train_X[sample])\n",
    "networkOutput = np.argmax(net.a[-1])\n",
    "networkOutput"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
